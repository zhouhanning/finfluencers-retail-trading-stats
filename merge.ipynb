{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fed9cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93002827",
   "metadata": {},
   "source": [
    "#### VIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c33fc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "vix = pd.read_csv('VIXCLS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7357b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vix_ready = vix.copy()\n",
    "vix_ready['observation_date'] = pd.to_datetime(vix_ready['observation_date'])\n",
    "vix_ready.rename(columns={'observation_date': 'date', 'VIXCLS': 'vix_close_price'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3bb26c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>vix_close_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>12.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>14.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>13.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>13.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>13.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  vix_close_price\n",
       "0 2020-01-02            12.47\n",
       "1 2020-01-03            14.02\n",
       "2 2020-01-06            13.85\n",
       "3 2020-01-07            13.79\n",
       "4 2020-01-08            13.45"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vix_ready.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f65aeff",
   "metadata": {},
   "source": [
    "#### fedrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "375df13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_rate = pd.read_csv('fed_rate_changes_2020_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "86cc2b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_rate['observation_date'] = pd.to_datetime(fed_rate['observation_date'])\n",
    "\n",
    "fed_ready = fed_rate[['observation_date', 'DFEDTARU']].rename(\n",
    "    columns={'observation_date': 'date', 'DFEDTARU': 'Fed_Rate'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3502346e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Fed_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-17</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-05</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Fed_Rate\n",
       "0 2020-01-01      1.75\n",
       "1 2020-03-04      1.25\n",
       "2 2020-03-16      0.25\n",
       "3 2022-03-17      0.50\n",
       "4 2022-05-05      1.00"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed_ready.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f2aa7c",
   "metadata": {},
   "source": [
    "#### SOFR (may not use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6fd86031",
   "metadata": {},
   "outputs": [],
   "source": [
    "sofr = pd.read_csv('sofr_2020_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1da4a195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Effective Date</th>\n",
       "      <th>Rate Type</th>\n",
       "      <th>Rate (%)</th>\n",
       "      <th>1st Percentile (%)</th>\n",
       "      <th>25th Percentile (%)</th>\n",
       "      <th>75th Percentile (%)</th>\n",
       "      <th>99th Percentile (%)</th>\n",
       "      <th>Volume ($Billions)</th>\n",
       "      <th>Target Rate From (%)</th>\n",
       "      <th>Target Rate To (%)</th>\n",
       "      <th>Intra Day - Low (%)</th>\n",
       "      <th>Intra Day - High (%)</th>\n",
       "      <th>Standard Deviation (%)</th>\n",
       "      <th>30-Day Average SOFR</th>\n",
       "      <th>90-Day Average SOFR</th>\n",
       "      <th>180-Day Average SOFR</th>\n",
       "      <th>SOFR Index</th>\n",
       "      <th>Revision Indicator (Y/N)</th>\n",
       "      <th>Footnote ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/30/2022</td>\n",
       "      <td>SOFR</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.48</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/29/2022</td>\n",
       "      <td>SOFR</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/28/2022</td>\n",
       "      <td>SOFR</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/27/2022</td>\n",
       "      <td>SOFR</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.40</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/23/2022</td>\n",
       "      <td>SOFR</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.38</td>\n",
       "      <td>991.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Effective Date Rate Type  Rate (%)  1st Percentile (%)  25th Percentile (%)  \\\n",
       "0     12/30/2022      SOFR       4.3                4.20                 4.26   \n",
       "1     12/29/2022      SOFR       4.3                4.20                 4.26   \n",
       "2     12/28/2022      SOFR       4.3                4.21                 4.27   \n",
       "3     12/27/2022      SOFR       4.3                4.15                 4.27   \n",
       "4     12/23/2022      SOFR       4.3                4.21                 4.26   \n",
       "\n",
       "   75th Percentile (%)  99th Percentile (%)  Volume ($Billions)  \\\n",
       "0                 4.33                 4.48              1004.0   \n",
       "1                 4.32                 4.45              1037.0   \n",
       "2                 4.32                 4.45              1005.0   \n",
       "3                 4.32                 4.40              1048.0   \n",
       "4                 4.31                 4.38               991.0   \n",
       "\n",
       "   Target Rate From (%)  Target Rate To (%)  Intra Day - Low (%)  \\\n",
       "0                   NaN                 NaN                  NaN   \n",
       "1                   NaN                 NaN                  NaN   \n",
       "2                   NaN                 NaN                  NaN   \n",
       "3                   NaN                 NaN                  NaN   \n",
       "4                   NaN                 NaN                  NaN   \n",
       "\n",
       "   Intra Day - High (%)  Standard Deviation (%)  30-Day Average SOFR  \\\n",
       "0                   NaN                     NaN                  NaN   \n",
       "1                   NaN                     NaN                  NaN   \n",
       "2                   NaN                     NaN                  NaN   \n",
       "3                   NaN                     NaN                  NaN   \n",
       "4                   NaN                     NaN                  NaN   \n",
       "\n",
       "   90-Day Average SOFR  180-Day Average SOFR  SOFR Index  \\\n",
       "0                  NaN                   NaN         NaN   \n",
       "1                  NaN                   NaN         NaN   \n",
       "2                  NaN                   NaN         NaN   \n",
       "3                  NaN                   NaN         NaN   \n",
       "4                  NaN                   NaN         NaN   \n",
       "\n",
       "   Revision Indicator (Y/N)  Footnote ID  \n",
       "0                       NaN          NaN  \n",
       "1                       NaN          NaN  \n",
       "2                       NaN          NaN  \n",
       "3                       NaN          NaN  \n",
       "4                       NaN          NaN  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sofr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fbcc1638",
   "metadata": {},
   "outputs": [],
   "source": [
    "sofr_ready = sofr[['Effective Date', 'Rate (%)']].copy()\n",
    "sofr_ready['Effective Date'] = pd.to_datetime(sofr_ready['Effective Date'])\n",
    "sofr_ready.rename(columns={'Effective Date': 'date', 'Rate (%)': 'sofr_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "447d2a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sofr_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  sofr_rate\n",
       "0 2022-12-30        4.3\n",
       "1 2022-12-29        4.3\n",
       "2 2022-12-28        4.3\n",
       "3 2022-12-27        4.3\n",
       "4 2022-12-23        4.3"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sofr_ready.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382b0d1f",
   "metadata": {},
   "source": [
    "#### News tone and sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7e9ebc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv('news_for 5_stocks.csv')\n",
    "news_ready = news.copy()\n",
    "news_ready['date'] = pd.to_datetime(news_ready['date'])\n",
    "news_ready.rename(columns={'date': 'date', 'ticker': 'stock_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "318b1fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>NewsCount</th>\n",
       "      <th>NewsTone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>268</td>\n",
       "      <td>0.003521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>240</td>\n",
       "      <td>-0.016863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>FB</td>\n",
       "      <td>2572</td>\n",
       "      <td>-0.011213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.010415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>276</td>\n",
       "      <td>-0.024558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date stock_name  NewsCount  NewsTone\n",
       "0 2020-01-01       AAPL        268  0.003521\n",
       "1 2020-01-01       AMZN        240 -0.016863\n",
       "2 2020-01-01         FB       2572 -0.011213\n",
       "3 2020-01-01       NVDA         16 -0.010415\n",
       "4 2020-01-01       TSLA        276 -0.024558"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_ready.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1ef9da",
   "metadata": {},
   "source": [
    "#### Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "89ba1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment = pd.read_csv('unemployment.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "02812a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_date</th>\n",
       "      <th>UNEMPLOY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>5869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>5753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>7206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>23084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>20929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  observation_date  UNEMPLOY\n",
       "0       2020-01-01      5869\n",
       "1       2020-02-01      5753\n",
       "2       2020-03-01      7206\n",
       "3       2020-04-01     23084\n",
       "4       2020-05-01     20929"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unemployment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "24796707",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_ready = unemployment.copy()\n",
    "unemployment_ready['observation_date'] = pd.to_datetime(unemployment_ready['observation_date'])\n",
    "unemployment_ready.rename(columns={'UNEMPLOY': 'unemployment', 'observation_date': 'date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2cc690ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>5869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>5753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>7206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>23084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>20929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  unemployment\n",
       "0 2020-01-01          5869\n",
       "1 2020-02-01          5753\n",
       "2 2020-03-01          7206\n",
       "3 2020-04-01         23084\n",
       "4 2020-05-01         20929"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unemployment_ready.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395a8e06",
   "metadata": {},
   "source": [
    "### FOMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "39615ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fomc = pd.read_csv('fomc_meetings_2020_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f4609cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>raw_date_text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>January</td>\n",
       "      <td>28-29</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>March</td>\n",
       "      <td>17-18 (cancelled)</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>April</td>\n",
       "      <td>28-29</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>June</td>\n",
       "      <td>9-10</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>July</td>\n",
       "      <td>28-29</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    month      raw_date_text  year\n",
       "0  2020-01-28  January              28-29  2020\n",
       "1  2020-03-17    March  17-18 (cancelled)  2020\n",
       "2  2020-04-28    April              28-29  2020\n",
       "3  2020-06-09     June               9-10  2020\n",
       "4  2020-07-28     July              28-29  2020"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fomc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "79cc6fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fomc_ready = fomc[['date', 'raw_date_text']].copy()\n",
    "\n",
    "fomc_ready['date'] = pd.to_datetime(fomc_ready['date'])\n",
    "\n",
    "# rule out cancelled meetings\n",
    "fomc_active = fomc_ready[~fomc_ready['raw_date_text'].str.contains('cancelled', case=False, na=False)].copy()\n",
    "\n",
    "fomc_dates_day1 = fomc_active['date']\n",
    "fomc_dates_day2 = fomc_active['date'] + pd.Timedelta(days=1)\n",
    "\n",
    "# Combine the two days into a single list of unique dates\n",
    "all_fomc_dates = pd.concat([fomc_dates_day1, fomc_dates_day2]).unique()\n",
    "\n",
    "# Convert to a set for easy lookup\n",
    "fomc_date_set = set(pd.to_datetime(all_fomc_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "145b4e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>raw_date_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>28-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>28-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>9-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>28-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-09-15</td>\n",
       "      <td>15-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date raw_date_text\n",
       "0 2020-01-28         28-29\n",
       "2 2020-04-28         28-29\n",
       "3 2020-06-09          9-10\n",
       "4 2020-07-28         28-29\n",
       "5 2020-09-15         15-16"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fomc_active.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94474360",
   "metadata": {},
   "source": [
    "#### stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9d1b9fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_price = pd.read_csv('Amazon_stock_price_2020_2022 - Sheet1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9ac89fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date   Open   High    Low  Close  Adj Close      Volume Stock_name\n",
      "0 2020-01-02  93.75  94.90  93.21  94.90      94.90  80580000.0       AMZN\n",
      "1 2020-01-03  93.22  94.31  93.22  93.75      93.75  75288000.0       AMZN\n",
      "2 2020-01-06     93  95.18  93.00  95.14      95.14  81236000.0       AMZN\n",
      "3 2020-01-07  95.22  95.69  94.60  95.34      95.34  80898000.0       AMZN\n",
      "4 2020-01-08   94.9  95.55  94.32  94.60      94.60  70160000.0       AMZN\n"
     ]
    }
   ],
   "source": [
    "amzn_ready = amzn_price.copy()\n",
    "\n",
    "amzn_ready.columns = [col.split('_')[-1] if '_' in col else col for col in amzn_ready.columns]\n",
    "\n",
    "amzn_ready['Date'] = pd.to_datetime(amzn_ready['Date'])\n",
    "amzn_ready = amzn_ready.sort_values('Date', ascending=True).reset_index(drop=True)\n",
    "\n",
    "amzn_ready['Volume'] = amzn_ready['Volume'].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "amzn_ready['Stock_name'] = 'AMZN'\n",
    "print(amzn_ready.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e0c2dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_price = pd.read_csv('Apple_stock_price_2020_2022 - Sheet1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "04e00aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date   Open   High    Low  Close  Adj Close       Volume Stock_name\n",
      "0 2020-01-02  74.06  75.15  73.80  75.09      72.47  135480400.0       AAPL\n",
      "1 2020-01-03  74.29  75.14  74.13  74.36      71.76  146322800.0       AAPL\n",
      "2 2020-01-06  73.45  74.99  73.19  74.95      72.34  118387200.0       AAPL\n",
      "3 2020-01-07  74.96  75.22  74.37  74.60      72.00  108872000.0       AAPL\n",
      "4 2020-01-08  74.29  76.11  74.29  75.80      73.15  132079200.0       AAPL\n"
     ]
    }
   ],
   "source": [
    "aapl_ready =aapl_price.copy()\n",
    "\n",
    "aapl_ready.columns = [col.split('_')[-1] if '_' in col else col for col in aapl_ready.columns]\n",
    "\n",
    "aapl_ready['Date'] = pd.to_datetime(aapl_ready['Date'])\n",
    "aapl_ready = aapl_ready.sort_values('Date', ascending=True).reset_index(drop=True)\n",
    "\n",
    "aapl_ready['Volume'] = aapl_ready['Volume'].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "aapl_ready['Stock_name'] = 'AAPL'\n",
    "print(aapl_ready.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8a023f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsla_price = pd.read_csv('TSLA_stock_price_2020_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0983f7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date   Open   High    Low  Close  Adj Close       Volume Stock_name\n",
      "0 2020-01-02   28.3  28.71  28.11  28.68      28.68  142981500.0       TSLA\n",
      "1 2020-01-03  29.37  30.27  29.13  29.53      29.53  266677500.0       TSLA\n",
      "2 2020-01-06  29.36  30.10  29.33  30.10      30.10  151995000.0       TSLA\n",
      "3 2020-01-07  30.76  31.44  30.22  31.27      31.27  268231500.0       TSLA\n",
      "4 2020-01-08  31.58  33.23  31.22  32.81      32.81  467164500.0       TSLA\n"
     ]
    }
   ],
   "source": [
    "tsla_ready =tsla_price.copy()\n",
    "\n",
    "tsla_ready.columns = [col.split('_')[-1] if '_' in col else col for col in tsla_ready.columns]\n",
    "\n",
    "tsla_ready['Date'] = pd.to_datetime(tsla_ready['Date'])\n",
    "tsla_ready = tsla_ready.sort_values('Date', ascending=True).reset_index(drop=True)\n",
    "\n",
    "tsla_ready['Volume'] = tsla_ready['Volume'].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "tsla_ready['Stock_name'] = 'TSLA'\n",
    "print(tsla_ready.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8e62ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_price = pd.read_csv('Meta_stock_price_2020_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6eb8e0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date    Open    High     Low   Close  Adj Close      Volume Stock_name\n",
      "0 2020-01-02  206.75  209.79  206.27  209.78     208.49  12077100.0         FB\n",
      "1 2020-01-03  207.21  210.40  206.95  208.67     207.39  11188400.0         FB\n",
      "2 2020-01-06  206.70  212.78  206.52  212.60     211.30  17058900.0         FB\n",
      "3 2020-01-07  212.82  214.58  211.75  213.06     211.75  14912400.0         FB\n",
      "4 2020-01-08  213.00  216.24  212.61  215.22     213.90  13475000.0         FB\n"
     ]
    }
   ],
   "source": [
    "meta_ready =meta_price.copy()\n",
    "\n",
    "meta_ready.columns = [col.split('_')[-1] if '_' in col else col for col in meta_ready.columns]\n",
    "\n",
    "meta_ready['Date'] = pd.to_datetime(meta_ready['Date'])\n",
    "meta_ready = meta_ready.sort_values('Date', ascending=True).reset_index(drop=True)\n",
    "\n",
    "meta_ready['Volume'] = meta_ready['Volume'].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "meta_ready['Stock_name'] = 'FB'\n",
    "print(meta_ready.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f8d92fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvda_price = pd.read_csv('NVDA_stock_price_2020_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f4486a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Open  High   Low  Close  Adj Close       Volume Stock_name\n",
      "0 2020-01-02  5.97  6.00  5.92   6.00       5.97  237536000.0       NVDA\n",
      "1 2020-01-03  5.88  5.95  5.85   5.90       5.88  205384000.0       NVDA\n",
      "2 2020-01-06  5.81  5.93  5.78   5.93       5.90  262636000.0       NVDA\n",
      "3 2020-01-07  5.95  6.04  5.91   6.00       5.97  314856000.0       NVDA\n",
      "4 2020-01-08  5.99  6.05  5.95   6.01       5.98  277108000.0       NVDA\n"
     ]
    }
   ],
   "source": [
    "nvda_ready =nvda_price.copy()\n",
    "\n",
    "nvda_ready.columns = [col.split('_')[-1] if '_' in col else col for col in nvda_ready.columns]\n",
    "\n",
    "nvda_ready['Date'] = pd.to_datetime(nvda_ready['Date'])\n",
    "nvda_ready = nvda_ready.sort_values('Date', ascending=True).reset_index(drop=True)\n",
    "\n",
    "nvda_ready['Volume'] = nvda_ready['Volume'].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "nvda_ready['Stock_name'] = 'NVDA'\n",
    "print(nvda_ready.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6916870b",
   "metadata": {},
   "source": [
    "#### Riskappetite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6f901ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_appetite = pd.read_csv('Sentiment_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3e7c497c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>2</th>\n",
       "      <th>Date</th>\n",
       "      <th>Bullish</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Bearish</th>\n",
       "      <th>Total</th>\n",
       "      <th>Mov Avg</th>\n",
       "      <th>Spread</th>\n",
       "      <th>Average</th>\n",
       "      <th>+St. Dev.</th>\n",
       "      <th>- St. Dev.</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-2-20</td>\n",
       "      <td>37.22%</td>\n",
       "      <td>40.91%</td>\n",
       "      <td>21.88%</td>\n",
       "      <td>100%</td>\n",
       "      <td>37.22%</td>\n",
       "      <td>15.3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3,247.93</td>\n",
       "      <td>3,212.03</td>\n",
       "      <td>3,230.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-9-20</td>\n",
       "      <td>33.07%</td>\n",
       "      <td>37.04%</td>\n",
       "      <td>29.89%</td>\n",
       "      <td>100%</td>\n",
       "      <td>35.14%</td>\n",
       "      <td>3.2%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3,267.07</td>\n",
       "      <td>3,212.03</td>\n",
       "      <td>3,253.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-16-20</td>\n",
       "      <td>41.83%</td>\n",
       "      <td>30.66%</td>\n",
       "      <td>27.51%</td>\n",
       "      <td>100%</td>\n",
       "      <td>37.37%</td>\n",
       "      <td>14.3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3,298.66</td>\n",
       "      <td>3,236.67</td>\n",
       "      <td>3,289.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-23-20</td>\n",
       "      <td>45.60%</td>\n",
       "      <td>29.63%</td>\n",
       "      <td>24.77%</td>\n",
       "      <td>100%</td>\n",
       "      <td>39.43%</td>\n",
       "      <td>20.8%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3,337.77</td>\n",
       "      <td>3,277.19</td>\n",
       "      <td>3,321.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-30-20</td>\n",
       "      <td>31.98%</td>\n",
       "      <td>31.17%</td>\n",
       "      <td>36.86%</td>\n",
       "      <td>100%</td>\n",
       "      <td>37.94%</td>\n",
       "      <td>-4.9%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3,337.77</td>\n",
       "      <td>3,234.50</td>\n",
       "      <td>3,273.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>11-28-24</td>\n",
       "      <td>37.05%</td>\n",
       "      <td>24.30%</td>\n",
       "      <td>38.65%</td>\n",
       "      <td>100%</td>\n",
       "      <td>42.67%</td>\n",
       "      <td>-1.6%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6,025.42</td>\n",
       "      <td>5,944.36</td>\n",
       "      <td>5,998.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>12-5-24</td>\n",
       "      <td>48.33%</td>\n",
       "      <td>21.00%</td>\n",
       "      <td>30.67%</td>\n",
       "      <td>100%</td>\n",
       "      <td>42.59%</td>\n",
       "      <td>17.7%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6,089.84</td>\n",
       "      <td>6,003.98</td>\n",
       "      <td>6,086.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>12-12-24</td>\n",
       "      <td>43.33%</td>\n",
       "      <td>25.00%</td>\n",
       "      <td>31.67%</td>\n",
       "      <td>100%</td>\n",
       "      <td>42.32%</td>\n",
       "      <td>11.7%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6,099.97</td>\n",
       "      <td>6,029.89</td>\n",
       "      <td>6,084.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>12-19-24</td>\n",
       "      <td>40.71%</td>\n",
       "      <td>27.86%</td>\n",
       "      <td>31.43%</td>\n",
       "      <td>100%</td>\n",
       "      <td>42.70%</td>\n",
       "      <td>9.3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6,085.19</td>\n",
       "      <td>5,867.79</td>\n",
       "      <td>5,872.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>12-26-24</td>\n",
       "      <td>37.80%</td>\n",
       "      <td>28.05%</td>\n",
       "      <td>34.15%</td>\n",
       "      <td>100%</td>\n",
       "      <td>42.49%</td>\n",
       "      <td>3.7%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6,040.10</td>\n",
       "      <td>5,832.30</td>\n",
       "      <td>6,040.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "2        Date Bullish Neutral Bearish Total Mov Avg Spread Average +St. Dev.  \\\n",
       "0      1-2-20  37.22%  40.91%  21.88%  100%  37.22%  15.3%     NaN       NaN   \n",
       "1      1-9-20  33.07%  37.04%  29.89%  100%  35.14%   3.2%     NaN       NaN   \n",
       "2     1-16-20  41.83%  30.66%  27.51%  100%  37.37%  14.3%     NaN       NaN   \n",
       "3     1-23-20  45.60%  29.63%  24.77%  100%  39.43%  20.8%     NaN       NaN   \n",
       "4     1-30-20  31.98%  31.17%  36.86%  100%  37.94%  -4.9%     NaN       NaN   \n",
       "..        ...     ...     ...     ...   ...     ...    ...     ...       ...   \n",
       "255  11-28-24  37.05%  24.30%  38.65%  100%  42.67%  -1.6%     NaN       NaN   \n",
       "256   12-5-24  48.33%  21.00%  30.67%  100%  42.59%  17.7%     NaN       NaN   \n",
       "257  12-12-24  43.33%  25.00%  31.67%  100%  42.32%  11.7%     NaN       NaN   \n",
       "258  12-19-24  40.71%  27.86%  31.43%  100%  42.70%   9.3%     NaN       NaN   \n",
       "259  12-26-24  37.80%  28.05%  34.15%  100%  42.49%   3.7%     NaN       NaN   \n",
       "\n",
       "2   - St. Dev.      High       Low     Close  NaN  NaN  NaN  \n",
       "0          NaN  3,247.93  3,212.03  3,230.78  NaN  NaN  NaN  \n",
       "1          NaN  3,267.07  3,212.03  3,253.05  NaN  NaN  NaN  \n",
       "2          NaN  3,298.66  3,236.67  3,289.29  NaN  NaN  NaN  \n",
       "3          NaN  3,337.77  3,277.19  3,321.75  NaN  NaN  NaN  \n",
       "4          NaN  3,337.77  3,234.50  3,273.40  NaN  NaN  NaN  \n",
       "..         ...       ...       ...       ...  ...  ...  ...  \n",
       "255        NaN  6,025.42  5,944.36  5,998.74  NaN  NaN  NaN  \n",
       "256        NaN  6,089.84  6,003.98  6,086.49  NaN  NaN  NaN  \n",
       "257        NaN  6,099.97  6,029.89  6,084.19  NaN  NaN  NaN  \n",
       "258        NaN  6,085.19  5,867.79  5,872.16  NaN  NaN  NaN  \n",
       "259        NaN  6,040.10  5,832.30  6,040.04  NaN  NaN  NaN  \n",
       "\n",
       "[260 rows x 16 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set row at index 2 as header and remove rows above it\n",
    "risk_appetite.columns = risk_appetite.iloc[2]\n",
    "risk_appetite = risk_appetite[3:].reset_index(drop=True)\n",
    "risk_appetite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c0ab9716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wt/c9dq7wk56lgb5n1hnwj_0glc0000gn/T/ipykernel_19139/4178870597.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  risk_appetite['Date'] = pd.to_datetime(risk_appetite['Date'])\n"
     ]
    }
   ],
   "source": [
    "risk_appetite['Date'] = pd.to_datetime(risk_appetite['Date']) \n",
    "\n",
    "# Convert percentage strings to numeric values\n",
    "# Convert to string first to handle both string and numeric values\n",
    "risk_appetite['Bullish'] = pd.to_numeric(risk_appetite['Bullish'].astype(str).str.rstrip('%'), errors='coerce')/100\n",
    "risk_appetite['Bearish'] = pd.to_numeric(risk_appetite['Bearish'].astype(str).str.rstrip('%'), errors='coerce')/100\n",
    "\n",
    "# Risk Appetite \n",
    "risk_appetite['RiskAppetite'] = risk_appetite['Bullish'] - risk_appetite['Bearish']\n",
    "\n",
    "aaii_clean = risk_appetite[['Date', 'RiskAppetite']].set_index('Date').sort_index()\n",
    "\n",
    "daily_risk_appetite = aaii_clean.resample('D').ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "11ca608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_ready = daily_risk_appetite.reset_index().rename(columns={'Date': 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4350d082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>2</th>\n",
       "      <th>date</th>\n",
       "      <th>RiskAppetite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0.1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0.1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0.1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0.1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>0.1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>0.1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>0.1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>0.0318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>0.0318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>0.0318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "2       date  RiskAppetite\n",
       "0 2020-01-02        0.1534\n",
       "1 2020-01-03        0.1534\n",
       "2 2020-01-04        0.1534\n",
       "3 2020-01-05        0.1534\n",
       "4 2020-01-06        0.1534\n",
       "5 2020-01-07        0.1534\n",
       "6 2020-01-08        0.1534\n",
       "7 2020-01-09        0.0318\n",
       "8 2020-01-10        0.0318\n",
       "9 2020-01-11        0.0318"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_ready.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faedb7eb",
   "metadata": {},
   "source": [
    "#### Stocktwits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "dc434ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /opt/miniconda3/envs/compss211/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/compss211/lib/python3.11/site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in /opt/miniconda3/envs/compss211/lib/python3.11/site-packages (from kagglehub) (6.0.3)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/compss211/lib/python3.11/site-packages (from kagglehub) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/compss211/lib/python3.11/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/compss211/lib/python3.11/site-packages (from requests->kagglehub) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/compss211/lib/python3.11/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/compss211/lib/python3.11/site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/compss211/lib/python3.11/site-packages (from requests->kagglehub) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "36f5a2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/gaoqianwen/.cache/kagglehub/datasets/frankcaoyun/stocktwits-2020-2022-raw/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"frankcaoyun/stocktwits-2020-2022-raw\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4613155d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /Users/gaoqianwen/.cache/kagglehub/datasets/frankcaoyun/stocktwits-2020-2022-raw/versions/1\n",
      "\n",
      "Files in the directory:\n",
      "  - StockTwits_2020_2022_Raw\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"Path: {path}\")\n",
    "print(\"\\nFiles in the directory:\")\n",
    "for item in os.listdir(path):\n",
    "    print(f\"  - {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "16030a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Symbol: AAPL ---\n",
      "  Found 62 CSV files for AAPL.\n",
      "  Found 62 CSV files for AAPL.\n",
      "  Reading & Filtering file 61/62...\n",
      "  Successfully merged AAPL. Final Shape (2020-2022): (914869, 17)\n",
      "\n",
      "--- Processing Symbol: AMZN ---\n",
      "  Found 90 CSV files for AMZN.\n",
      "  Reading & Filtering file 1/90...\n",
      "  Successfully merged AAPL. Final Shape (2020-2022): (914869, 17)\n",
      "\n",
      "--- Processing Symbol: AMZN ---\n",
      "  Found 90 CSV files for AMZN.\n",
      "  Reading & Filtering file 81/90...\n",
      "  Successfully merged AMZN. Final Shape (2020-2022): (477187, 16)\n",
      "\n",
      "--- Processing Symbol: TSLA ---\n",
      "  Found 147 CSV files for TSLA.\n",
      "  Reading & Filtering file 1/147...\n",
      "  Successfully merged AMZN. Final Shape (2020-2022): (477187, 16)\n",
      "\n",
      "--- Processing Symbol: TSLA ---\n",
      "  Found 147 CSV files for TSLA.\n",
      "  Reading & Filtering file 141/147...\n",
      "  Successfully merged TSLA. Final Shape (2020-2022): (2197536, 17)\n",
      "\n",
      "--- Processing Symbol: MSFT ---\n",
      "  Found 0 CSV files for MSFT.\n",
      "  Warning: No files found for MSFT. Skipping...\n",
      "\n",
      "--- Processing Symbol: GOOGL ---\n",
      "  Found 0 CSV files for GOOGL.\n",
      "  Warning: No files found for GOOGL. Skipping...\n",
      "\n",
      "--- Processing Symbol: FB ---\n",
      "  Found 24 CSV files for FB.\n",
      "\n",
      "  Successfully merged TSLA. Final Shape (2020-2022): (2197536, 17)\n",
      "\n",
      "--- Processing Symbol: MSFT ---\n",
      "  Found 0 CSV files for MSFT.\n",
      "  Warning: No files found for MSFT. Skipping...\n",
      "\n",
      "--- Processing Symbol: GOOGL ---\n",
      "  Found 0 CSV files for GOOGL.\n",
      "  Warning: No files found for GOOGL. Skipping...\n",
      "\n",
      "--- Processing Symbol: FB ---\n",
      "  Found 24 CSV files for FB.\n",
      "  Reading & Filtering file 21/24...\n",
      "  Successfully merged FB. Final Shape (2020-2022): (324398, 16)\n",
      "\n",
      "--- Processing Symbol: NVDA ---\n",
      "  Found 39 CSV files for NVDA.\n",
      "  Reading & Filtering file 1/39...\n",
      "  Successfully merged FB. Final Shape (2020-2022): (324398, 16)\n",
      "\n",
      "--- Processing Symbol: NVDA ---\n",
      "  Found 39 CSV files for NVDA.\n",
      "  Reading & Filtering file 31/39...\n",
      "  Successfully merged NVDA. Final Shape (2020-2022): (251959, 17)\n",
      "\n",
      "--- Finalizing Master Dataset ---\n",
      "\n",
      "  Successfully merged NVDA. Final Shape (2020-2022): (251959, 17)\n",
      "\n",
      "--- Finalizing Master Dataset ---\n",
      "Total Shape: (4165949, 17)\n",
      "Date Range: 2020-01-01 00:00:25+00:00 to 2022-03-05 14:16:48+00:00\n",
      "Total Shape: (4165949, 17)\n",
      "Date Range: 2020-01-01 00:00:25+00:00 to 2022-03-05 14:16:48+00:00\n",
      "Unique stocks: ['AAPL' 'AMZN' 'TSLA' 'FB' 'NVDA']\n",
      "   Unnamed: 0         id                                               body  \\\n",
      "0           0  264350906  $AAPL sold my AAPL $124 &quot;yesterday of cou...   \n",
      "1           1  264350850                           $AAPL Moving fast early!   \n",
      "2           2  264350821                    $AAPL if confirms daily can rip   \n",
      "3           3  264350809                            $AAPL patience pays off   \n",
      "4           4  264350762  2020-12-15 14:39:50+00:00 $AAPL, $CMCSA, $SWKS...   \n",
      "\n",
      "                 created_at  \\\n",
      "0 2020-12-15 14:40:07+00:00   \n",
      "1 2020-12-15 14:40:00+00:00   \n",
      "2 2020-12-15 14:39:57+00:00   \n",
      "3 2020-12-15 14:39:55+00:00   \n",
      "4 2020-12-15 14:39:50+00:00   \n",
      "\n",
      "                                                user  \\\n",
      "0  {'id': 410481, 'username': 'Navyman', 'name': ...   \n",
      "1  {'id': 1563546, 'username': 'Trader_Ty', 'name...   \n",
      "2  {'id': 24272, 'username': 'danshep55', 'name':...   \n",
      "3  {'id': 763412, 'username': 'zeketrades_', 'nam...   \n",
      "4  {'id': 1511377, 'username': 'YuMiStocks_Trade'...   \n",
      "\n",
      "                                              source  \\\n",
      "0  {'id': 2269, 'title': 'StockTwits Web', 'url':...   \n",
      "1  {'id': 2269, 'title': 'StockTwits Web', 'url':...   \n",
      "2  {'id': 1149, 'title': 'StockTwits for iOS', 'u...   \n",
      "3  {'id': 1149, 'title': 'StockTwits for iOS', 'u...   \n",
      "4  {'id': 5846, 'title': 'ConfluxBot', 'url': 'ht...   \n",
      "\n",
      "                                             symbols  \\\n",
      "0  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
      "1  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
      "2  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
      "3  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
      "4  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
      "\n",
      "                                        conversation mentioned_users  \\\n",
      "0  {'parent_message_id': 264350906, 'in_reply_to_...              []   \n",
      "1                                                NaN              []   \n",
      "2                                                NaN              []   \n",
      "3                                                NaN              []   \n",
      "4                                                NaN              []   \n",
      "\n",
      "                              entities  \\\n",
      "0                  {'sentiment': None}   \n",
      "1  {'sentiment': {'basic': 'Bullish'}}   \n",
      "2  {'sentiment': {'basic': 'Bullish'}}   \n",
      "3                  {'sentiment': None}   \n",
      "4                  {'sentiment': None}   \n",
      "\n",
      "                                               likes  \\\n",
      "0                                                NaN   \n",
      "1  {'total': 3, 'user_ids': [683907, 3602081, 309...   \n",
      "2                                                NaN   \n",
      "3        {'total': 2, 'user_ids': [1703700, 617630]}   \n",
      "4                {'total': 1, 'user_ids': [4252585]}   \n",
      "\n",
      "                                      reshares reshare_message links  \\\n",
      "0                                          NaN             NaN   NaN   \n",
      "1                                          NaN             NaN   NaN   \n",
      "2  {'reshared_count': 1, 'user_ids': [184733]}             NaN   NaN   \n",
      "3                                          NaN             NaN   NaN   \n",
      "4                                          NaN             NaN   NaN   \n",
      "\n",
      "  stock_name owned_symbols structurable  \n",
      "0       AAPL           NaN          NaN  \n",
      "1       AAPL           NaN          NaN  \n",
      "2       AAPL           NaN          NaN  \n",
      "3       AAPL           NaN          NaN  \n",
      "4       AAPL           NaN          NaN  \n",
      "Unique stocks: ['AAPL' 'AMZN' 'TSLA' 'FB' 'NVDA']\n",
      "   Unnamed: 0         id                                               body  \\\n",
      "0           0  264350906  $AAPL sold my AAPL $124 &quot;yesterday of cou...   \n",
      "1           1  264350850                           $AAPL Moving fast early!   \n",
      "2           2  264350821                    $AAPL if confirms daily can rip   \n",
      "3           3  264350809                            $AAPL patience pays off   \n",
      "4           4  264350762  2020-12-15 14:39:50+00:00 $AAPL, $CMCSA, $SWKS...   \n",
      "\n",
      "                 created_at  \\\n",
      "0 2020-12-15 14:40:07+00:00   \n",
      "1 2020-12-15 14:40:00+00:00   \n",
      "2 2020-12-15 14:39:57+00:00   \n",
      "3 2020-12-15 14:39:55+00:00   \n",
      "4 2020-12-15 14:39:50+00:00   \n",
      "\n",
      "                                                user  \\\n",
      "0  {'id': 410481, 'username': 'Navyman', 'name': ...   \n",
      "1  {'id': 1563546, 'username': 'Trader_Ty', 'name...   \n",
      "2  {'id': 24272, 'username': 'danshep55', 'name':...   \n",
      "3  {'id': 763412, 'username': 'zeketrades_', 'nam...   \n",
      "4  {'id': 1511377, 'username': 'YuMiStocks_Trade'...   \n",
      "\n",
      "                                              source  \\\n",
      "0  {'id': 2269, 'title': 'StockTwits Web', 'url':...   \n",
      "1  {'id': 2269, 'title': 'StockTwits Web', 'url':...   \n",
      "2  {'id': 1149, 'title': 'StockTwits for iOS', 'u...   \n",
      "3  {'id': 1149, 'title': 'StockTwits for iOS', 'u...   \n",
      "4  {'id': 5846, 'title': 'ConfluxBot', 'url': 'ht...   \n",
      "\n",
      "                                             symbols  \\\n",
      "0  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
      "1  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
      "2  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
      "3  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
      "4  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
      "\n",
      "                                        conversation mentioned_users  \\\n",
      "0  {'parent_message_id': 264350906, 'in_reply_to_...              []   \n",
      "1                                                NaN              []   \n",
      "2                                                NaN              []   \n",
      "3                                                NaN              []   \n",
      "4                                                NaN              []   \n",
      "\n",
      "                              entities  \\\n",
      "0                  {'sentiment': None}   \n",
      "1  {'sentiment': {'basic': 'Bullish'}}   \n",
      "2  {'sentiment': {'basic': 'Bullish'}}   \n",
      "3                  {'sentiment': None}   \n",
      "4                  {'sentiment': None}   \n",
      "\n",
      "                                               likes  \\\n",
      "0                                                NaN   \n",
      "1  {'total': 3, 'user_ids': [683907, 3602081, 309...   \n",
      "2                                                NaN   \n",
      "3        {'total': 2, 'user_ids': [1703700, 617630]}   \n",
      "4                {'total': 1, 'user_ids': [4252585]}   \n",
      "\n",
      "                                      reshares reshare_message links  \\\n",
      "0                                          NaN             NaN   NaN   \n",
      "1                                          NaN             NaN   NaN   \n",
      "2  {'reshared_count': 1, 'user_ids': [184733]}             NaN   NaN   \n",
      "3                                          NaN             NaN   NaN   \n",
      "4                                          NaN             NaN   NaN   \n",
      "\n",
      "  stock_name owned_symbols structurable  \n",
      "0       AAPL           NaN          NaN  \n",
      "1       AAPL           NaN          NaN  \n",
      "2       AAPL           NaN          NaN  \n",
      "3       AAPL           NaN          NaN  \n",
      "4       AAPL           NaN          NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# 1. Define dataset path\n",
    "# Ensure this 'path' variable matches your kagglehub download path\n",
    "base_path = path \n",
    "\n",
    "# 2. Define Target Stocks\n",
    "# Adjusted based on your screenshot (Included FB and NVDA since they are in the folder)\n",
    "# You can remove them if you only want the original list\n",
    "target_symbols = ['AAPL', 'AMZN', 'TSLA', 'MSFT', 'GOOGL', 'FB', 'NVDA']\n",
    "\n",
    "# Dictionary to store results\n",
    "stock_data_dict = {}\n",
    "\n",
    "def process_and_filter_stock(symbol, root_directory):\n",
    "    \"\"\"\n",
    "    Finds files, merges them, and filters data to keep ONLY 2020-2022.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Processing Symbol: {symbol} ---\")\n",
    "    \n",
    "    # A. Robust Search Pattern\n",
    "    # Matches 'AAPL_...', 'AMZN2019...', 'TSLA...' regardless of underscores\n",
    "    # Logic: Find any file containing the symbol string recursively\n",
    "    search_pattern = os.path.join(root_directory, \"**\", f\"*{symbol}*.csv\")\n",
    "    files_found = glob.glob(search_pattern, recursive=True)\n",
    "    \n",
    "    # Try lowercase if uppercase fails\n",
    "    if not files_found:\n",
    "        search_pattern_lower = os.path.join(root_directory, \"**\", f\"*{symbol.lower()}*.csv\")\n",
    "        files_found = glob.glob(search_pattern_lower, recursive=True)\n",
    "        \n",
    "    print(f\"  Found {len(files_found)} CSV files for {symbol}.\")\n",
    "    \n",
    "    if not files_found:\n",
    "        print(f\"  Warning: No files found for {symbol}. Skipping...\")\n",
    "        return None\n",
    "    \n",
    "    temp_dfs = []\n",
    "    \n",
    "    # B. Read and Merge\n",
    "    for i, file_path in enumerate(files_found):\n",
    "        try:\n",
    "            # Read CSV (skipping bad lines to prevent crashes)\n",
    "            df = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "            \n",
    "            # Ensure 'created_at' column exists (key for filtering)\n",
    "            if 'created_at' in df.columns:\n",
    "                # C. Time Filtering (The Crucial Step)\n",
    "                # Convert to datetime\n",
    "                df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "                \n",
    "                # Filter: Keep only data between 2020-01-01 and 2022-12-31\n",
    "                # This removes the 2013-2019 data from AMZN/NVDA folders\n",
    "                mask = (df['created_at'].dt.year >= 2020) & (df['created_at'].dt.year <= 2022)\n",
    "                df_filtered = df.loc[mask].copy()\n",
    "                \n",
    "                # Only append if there is data left after filtering\n",
    "                if not df_filtered.empty:\n",
    "                    df_filtered['stock_name'] = symbol # Tag the stock\n",
    "                    temp_dfs.append(df_filtered)\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(f\"  Reading & Filtering file {i+1}/{len(files_found)}...\", end='\\r')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Error reading {file_path}: {e}\")\n",
    "            \n",
    "    # D. Final Concatenation for this Stock\n",
    "    if temp_dfs:\n",
    "        combined_df = pd.concat(temp_dfs, ignore_index=True)\n",
    "        print(f\"\\n  Successfully merged {symbol}. Final Shape (2020-2022): {combined_df.shape}\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(f\"\\n  No data remained for {symbol} after 2020-2022 filtering.\")\n",
    "        return None\n",
    "\n",
    "# 3. Execution Loop\n",
    "for sym in target_symbols:\n",
    "    df_result = process_and_filter_stock(sym, base_path)\n",
    "    if df_result is not None:\n",
    "        stock_data_dict[sym] = df_result\n",
    "\n",
    "# 4. Combine Everything\n",
    "print(\"\\n--- Finalizing Master Dataset ---\")\n",
    "if stock_data_dict:\n",
    "    all_stocks_df = pd.concat(stock_data_dict.values(), ignore_index=True)\n",
    "    \n",
    "    # Double check the date range\n",
    "    print(f\"Total Shape: {all_stocks_df.shape}\")\n",
    "    print(f\"Date Range: {all_stocks_df['created_at'].min()} to {all_stocks_df['created_at'].max()}\")\n",
    "    print(\"Unique stocks:\", all_stocks_df['stock_name'].unique())\n",
    "    \n",
    "    # Preview\n",
    "    print(all_stocks_df.head())\n",
    "else:\n",
    "    print(\"No data processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f055dc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'id', 'body', 'created_at', 'user', 'source', 'symbols',\n",
      "       'conversation', 'mentioned_users', 'entities', 'likes', 'reshares',\n",
      "       'reshare_message', 'links', 'stock_name', 'owned_symbols',\n",
      "       'structurable'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(all_stocks_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "51bf62fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user</th>\n",
       "      <th>source</th>\n",
       "      <th>symbols</th>\n",
       "      <th>conversation</th>\n",
       "      <th>mentioned_users</th>\n",
       "      <th>entities</th>\n",
       "      <th>likes</th>\n",
       "      <th>reshares</th>\n",
       "      <th>reshare_message</th>\n",
       "      <th>links</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>owned_symbols</th>\n",
       "      <th>structurable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>264350906</td>\n",
       "      <td>$AAPL sold my AAPL $124 &amp;quot;yesterday of cou...</td>\n",
       "      <td>2020-12-15 14:40:07+00:00</td>\n",
       "      <td>{'id': 410481, 'username': 'Navyman', 'name': ...</td>\n",
       "      <td>{'id': 2269, 'title': 'StockTwits Web', 'url':...</td>\n",
       "      <td>[{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...</td>\n",
       "      <td>{'parent_message_id': 264350906, 'in_reply_to_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'sentiment': None}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>264350850</td>\n",
       "      <td>$AAPL Moving fast early!</td>\n",
       "      <td>2020-12-15 14:40:00+00:00</td>\n",
       "      <td>{'id': 1563546, 'username': 'Trader_Ty', 'name...</td>\n",
       "      <td>{'id': 2269, 'title': 'StockTwits Web', 'url':...</td>\n",
       "      <td>[{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'sentiment': {'basic': 'Bullish'}}</td>\n",
       "      <td>{'total': 3, 'user_ids': [683907, 3602081, 309...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>264350821</td>\n",
       "      <td>$AAPL if confirms daily can rip</td>\n",
       "      <td>2020-12-15 14:39:57+00:00</td>\n",
       "      <td>{'id': 24272, 'username': 'danshep55', 'name':...</td>\n",
       "      <td>{'id': 1149, 'title': 'StockTwits for iOS', 'u...</td>\n",
       "      <td>[{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'sentiment': {'basic': 'Bullish'}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'reshared_count': 1, 'user_ids': [184733]}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>264350809</td>\n",
       "      <td>$AAPL patience pays off</td>\n",
       "      <td>2020-12-15 14:39:55+00:00</td>\n",
       "      <td>{'id': 763412, 'username': 'zeketrades_', 'nam...</td>\n",
       "      <td>{'id': 1149, 'title': 'StockTwits for iOS', 'u...</td>\n",
       "      <td>[{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'sentiment': None}</td>\n",
       "      <td>{'total': 2, 'user_ids': [1703700, 617630]}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>264350762</td>\n",
       "      <td>2020-12-15 14:39:50+00:00 $AAPL, $CMCSA, $SWKS...</td>\n",
       "      <td>2020-12-15 14:39:50+00:00</td>\n",
       "      <td>{'id': 1511377, 'username': 'YuMiStocks_Trade'...</td>\n",
       "      <td>{'id': 5846, 'title': 'ConfluxBot', 'url': 'ht...</td>\n",
       "      <td>[{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'sentiment': None}</td>\n",
       "      <td>{'total': 1, 'user_ids': [4252585]}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id                                               body  \\\n",
       "0           0  264350906  $AAPL sold my AAPL $124 &quot;yesterday of cou...   \n",
       "1           1  264350850                           $AAPL Moving fast early!   \n",
       "2           2  264350821                    $AAPL if confirms daily can rip   \n",
       "3           3  264350809                            $AAPL patience pays off   \n",
       "4           4  264350762  2020-12-15 14:39:50+00:00 $AAPL, $CMCSA, $SWKS...   \n",
       "\n",
       "                 created_at  \\\n",
       "0 2020-12-15 14:40:07+00:00   \n",
       "1 2020-12-15 14:40:00+00:00   \n",
       "2 2020-12-15 14:39:57+00:00   \n",
       "3 2020-12-15 14:39:55+00:00   \n",
       "4 2020-12-15 14:39:50+00:00   \n",
       "\n",
       "                                                user  \\\n",
       "0  {'id': 410481, 'username': 'Navyman', 'name': ...   \n",
       "1  {'id': 1563546, 'username': 'Trader_Ty', 'name...   \n",
       "2  {'id': 24272, 'username': 'danshep55', 'name':...   \n",
       "3  {'id': 763412, 'username': 'zeketrades_', 'nam...   \n",
       "4  {'id': 1511377, 'username': 'YuMiStocks_Trade'...   \n",
       "\n",
       "                                              source  \\\n",
       "0  {'id': 2269, 'title': 'StockTwits Web', 'url':...   \n",
       "1  {'id': 2269, 'title': 'StockTwits Web', 'url':...   \n",
       "2  {'id': 1149, 'title': 'StockTwits for iOS', 'u...   \n",
       "3  {'id': 1149, 'title': 'StockTwits for iOS', 'u...   \n",
       "4  {'id': 5846, 'title': 'ConfluxBot', 'url': 'ht...   \n",
       "\n",
       "                                             symbols  \\\n",
       "0  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
       "1  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
       "2  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
       "3  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
       "4  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
       "\n",
       "                                        conversation mentioned_users  \\\n",
       "0  {'parent_message_id': 264350906, 'in_reply_to_...              []   \n",
       "1                                                NaN              []   \n",
       "2                                                NaN              []   \n",
       "3                                                NaN              []   \n",
       "4                                                NaN              []   \n",
       "\n",
       "                              entities  \\\n",
       "0                  {'sentiment': None}   \n",
       "1  {'sentiment': {'basic': 'Bullish'}}   \n",
       "2  {'sentiment': {'basic': 'Bullish'}}   \n",
       "3                  {'sentiment': None}   \n",
       "4                  {'sentiment': None}   \n",
       "\n",
       "                                               likes  \\\n",
       "0                                                NaN   \n",
       "1  {'total': 3, 'user_ids': [683907, 3602081, 309...   \n",
       "2                                                NaN   \n",
       "3        {'total': 2, 'user_ids': [1703700, 617630]}   \n",
       "4                {'total': 1, 'user_ids': [4252585]}   \n",
       "\n",
       "                                      reshares reshare_message links  \\\n",
       "0                                          NaN             NaN   NaN   \n",
       "1                                          NaN             NaN   NaN   \n",
       "2  {'reshared_count': 1, 'user_ids': [184733]}             NaN   NaN   \n",
       "3                                          NaN             NaN   NaN   \n",
       "4                                          NaN             NaN   NaN   \n",
       "\n",
       "  stock_name owned_symbols structurable  \n",
       "0       AAPL           NaN          NaN  \n",
       "1       AAPL           NaN          NaN  \n",
       "2       AAPL           NaN          NaN  \n",
       "3       AAPL           NaN          NaN  \n",
       "4       AAPL           NaN          NaN  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stocks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f27dc7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics grouped by stock_name:\n",
      "================================================================================\n",
      "\n",
      "Number of observations per stock:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_name\n",
      "AAPL     914869\n",
      "AMZN     477187\n",
      "FB       324398\n",
      "NVDA     251959\n",
      "TSLA    2197536\n",
      "dtype: int64\n",
      "\n",
      "================================================================================\n",
      "Descriptive statistics by stock:\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Stock: AAPL\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Stock: AAPL\n",
      "================================================================================\n",
      "Total records: 914,869\n",
      "Date range: 2020-01-01 00:00:25+00:00 to 2022-02-27 15:17:51+00:00\n",
      "\n",
      "Key columns summary:\n",
      "          Unnamed: 0            id\n",
      "count  914869.000000  9.148690e+05\n",
      "mean     7454.940278  2.947062e+08\n",
      "std      4328.251718  7.362931e+07\n",
      "min         0.000000  1.886133e+08\n",
      "25%      3694.000000  2.400268e+08\n",
      "50%      7443.000000  2.735484e+08\n",
      "75%     11193.000000  3.571643e+08\n",
      "max     14999.000000  4.397107e+08\n",
      "\n",
      "================================================================================\n",
      "Stock: AMZN\n",
      "================================================================================\n",
      "Total records: 914,869\n",
      "Date range: 2020-01-01 00:00:25+00:00 to 2022-02-27 15:17:51+00:00\n",
      "\n",
      "Key columns summary:\n",
      "          Unnamed: 0            id\n",
      "count  914869.000000  9.148690e+05\n",
      "mean     7454.940278  2.947062e+08\n",
      "std      4328.251718  7.362931e+07\n",
      "min         0.000000  1.886133e+08\n",
      "25%      3694.000000  2.400268e+08\n",
      "50%      7443.000000  2.735484e+08\n",
      "75%     11193.000000  3.571643e+08\n",
      "max     14999.000000  4.397107e+08\n",
      "\n",
      "================================================================================\n",
      "Stock: AMZN\n",
      "================================================================================\n",
      "Total records: 477,187\n",
      "Date range: 2020-01-01 00:05:16+00:00 to 2022-03-05 14:16:48+00:00\n",
      "\n",
      "Key columns summary:\n",
      "          Unnamed: 0            id\n",
      "count  477187.000000  4.771870e+05\n",
      "mean     2990.047543  3.027450e+08\n",
      "std      1731.634494  7.981667e+07\n",
      "min         0.000000  1.886136e+08\n",
      "25%      1491.000000  2.328728e+08\n",
      "50%      2982.000000  2.830584e+08\n",
      "75%      4489.000000  3.747159e+08\n",
      "max      5999.000000  4.415241e+08\n",
      "\n",
      "================================================================================\n",
      "Stock: TSLA\n",
      "================================================================================\n",
      "Total records: 477,187\n",
      "Date range: 2020-01-01 00:05:16+00:00 to 2022-03-05 14:16:48+00:00\n",
      "\n",
      "Key columns summary:\n",
      "          Unnamed: 0            id\n",
      "count  477187.000000  4.771870e+05\n",
      "mean     2990.047543  3.027450e+08\n",
      "std      1731.634494  7.981667e+07\n",
      "min         0.000000  1.886136e+08\n",
      "25%      1491.000000  2.328728e+08\n",
      "50%      2982.000000  2.830584e+08\n",
      "75%      4489.000000  3.747159e+08\n",
      "max      5999.000000  4.415241e+08\n",
      "\n",
      "================================================================================\n",
      "Stock: TSLA\n",
      "================================================================================\n",
      "Total records: 2,197,536\n",
      "Date range: 2020-01-01 00:00:40+00:00 to 2022-03-01 01:57:34+00:00\n",
      "\n",
      "Key columns summary:\n",
      "Total records: 2,197,536\n",
      "Date range: 2020-01-01 00:00:40+00:00 to 2022-03-01 01:57:34+00:00\n",
      "\n",
      "Key columns summary:\n",
      "         Unnamed: 0            id\n",
      "count  2.197536e+06  2.197536e+06\n",
      "mean   7.486411e+03  2.936634e+08\n",
      "std    4.329819e+03  7.688598e+07\n",
      "min    0.000000e+00  1.886133e+08\n",
      "25%    3.737000e+03  2.361209e+08\n",
      "50%    7.474000e+03  2.701553e+08\n",
      "75%    1.123600e+04  3.591259e+08\n",
      "max    1.499900e+04  4.401076e+08\n",
      "\n",
      "================================================================================\n",
      "Stock: FB\n",
      "================================================================================\n",
      "         Unnamed: 0            id\n",
      "count  2.197536e+06  2.197536e+06\n",
      "mean   7.486411e+03  2.936634e+08\n",
      "std    4.329819e+03  7.688598e+07\n",
      "min    0.000000e+00  1.886133e+08\n",
      "25%    3.737000e+03  2.361209e+08\n",
      "50%    7.474000e+03  2.701553e+08\n",
      "75%    1.123600e+04  3.591259e+08\n",
      "max    1.499900e+04  4.401076e+08\n",
      "\n",
      "================================================================================\n",
      "Stock: FB\n",
      "================================================================================\n",
      "Total records: 324,398\n",
      "Date range: 2020-01-01 00:25:57+00:00 to 2022-03-05 06:34:16+00:00\n",
      "\n",
      "Key columns summary:\n",
      "          Unnamed: 0            id\n",
      "count  324398.000000  3.243980e+05\n",
      "mean     7418.267092  3.301023e+08\n",
      "std      4317.403140  8.812126e+07\n",
      "min         0.000000  1.886147e+08\n",
      "25%      3686.000000  2.432278e+08\n",
      "50%      7372.000000  3.417579e+08\n",
      "75%     11137.000000  4.220118e+08\n",
      "max     14999.000000  4.415061e+08\n",
      "\n",
      "================================================================================\n",
      "Stock: NVDA\n",
      "================================================================================\n",
      "Total records: 324,398\n",
      "Date range: 2020-01-01 00:25:57+00:00 to 2022-03-05 06:34:16+00:00\n",
      "\n",
      "Key columns summary:\n",
      "          Unnamed: 0            id\n",
      "count  324398.000000  3.243980e+05\n",
      "mean     7418.267092  3.301023e+08\n",
      "std      4317.403140  8.812126e+07\n",
      "min         0.000000  1.886147e+08\n",
      "25%      3686.000000  2.432278e+08\n",
      "50%      7372.000000  3.417579e+08\n",
      "75%     11137.000000  4.220118e+08\n",
      "max     14999.000000  4.415061e+08\n",
      "\n",
      "================================================================================\n",
      "Stock: NVDA\n",
      "================================================================================\n",
      "Total records: 251,959\n",
      "Date range: 2020-01-01 00:37:39+00:00 to 2022-02-28 14:54:52+00:00\n",
      "\n",
      "Key columns summary:\n",
      "          Unnamed: 0            id\n",
      "count  251959.000000  2.519590e+05\n",
      "mean     7427.270615  3.396631e+08\n",
      "std      4304.602292  8.086960e+07\n",
      "min         0.000000  1.886153e+08\n",
      "25%      3705.000000  2.568196e+08\n",
      "50%      7410.000000  3.593081e+08\n",
      "75%     11115.000000  4.112893e+08\n",
      "max     14999.000000  4.398812e+08\n",
      "Total records: 251,959\n",
      "Date range: 2020-01-01 00:37:39+00:00 to 2022-02-28 14:54:52+00:00\n",
      "\n",
      "Key columns summary:\n",
      "          Unnamed: 0            id\n",
      "count  251959.000000  2.519590e+05\n",
      "mean     7427.270615  3.396631e+08\n",
      "std      4304.602292  8.086960e+07\n",
      "min         0.000000  1.886153e+08\n",
      "25%      3705.000000  2.568196e+08\n",
      "50%      7410.000000  3.593081e+08\n",
      "75%     11115.000000  4.112893e+08\n",
      "max     14999.000000  4.398812e+08\n"
     ]
    }
   ],
   "source": [
    "# Group by stock_name and show descriptive statistics\n",
    "print(\"Data statistics grouped by stock_name:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Count observations per stock\n",
    "print(\"\\nNumber of observations per stock:\")\n",
    "print(all_stocks_df.groupby('stock_name').size())\n",
    "\n",
    "# Show basic statistics for each stock\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Descriptive statistics by stock:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for stock in all_stocks_df['stock_name'].unique():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Stock: {stock}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    stock_data = all_stocks_df[all_stocks_df['stock_name'] == stock]\n",
    "    print(f\"Total records: {len(stock_data):,}\")\n",
    "    print(f\"Date range: {stock_data['created_at'].min()} to {stock_data['created_at'].max()}\")\n",
    "    \n",
    "    # Show sentiment distribution if available\n",
    "    if 'sentiment' in stock_data.columns:\n",
    "        print(f\"\\nSentiment distribution:\")\n",
    "        print(stock_data['sentiment'].value_counts())\n",
    "    \n",
    "    # Show other key statistics\n",
    "    print(f\"\\nKey columns summary:\")\n",
    "    print(stock_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d0f68b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data to 2020-01-01 to 2022-02-26\n",
      "Original shape: (4165949, 17)\n",
      "Filtered shape: (4155893, 17)\n",
      "\n",
      "Date Range: 2020-01-01 00:00:25+00:00 to 2022-02-26 23:59:00+00:00\n",
      "\n",
      "Records per stock after filtering:\n",
      "\n",
      "Date Range: 2020-01-01 00:00:25+00:00 to 2022-02-26 23:59:00+00:00\n",
      "\n",
      "Records per stock after filtering:\n",
      "stock_name\n",
      "AAPL     914778\n",
      "AMZN     474823\n",
      "FB       320670\n",
      "NVDA     251666\n",
      "TSLA    2193956\n",
      "dtype: int64\n",
      "stock_name\n",
      "AAPL     914778\n",
      "AMZN     474823\n",
      "FB       320670\n",
      "NVDA     251666\n",
      "TSLA    2193956\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter all stocks to the same date range: 2020-01-01 to 2022-02-26\n",
    "start_date = pd.to_datetime('2020-01-01 00:00:00+00:00')\n",
    "end_date = pd.to_datetime('2022-02-26 23:59:59+00:00')\n",
    "\n",
    "# Filter the data\n",
    "all_stocks_df_filtered = all_stocks_df[\n",
    "    (all_stocks_df['created_at'] >= start_date) & \n",
    "    (all_stocks_df['created_at'] <= end_date)\n",
    "].copy()\n",
    "\n",
    "print(\"Filtered data to 2020-01-01 to 2022-02-26\")\n",
    "print(f\"Original shape: {all_stocks_df.shape}\")\n",
    "print(f\"Filtered shape: {all_stocks_df_filtered.shape}\")\n",
    "print(f\"\\nDate Range: {all_stocks_df_filtered['created_at'].min()} to {all_stocks_df_filtered['created_at'].max()}\")\n",
    "print(f\"\\nRecords per stock after filtering:\")\n",
    "print(all_stocks_df_filtered.groupby('stock_name').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8bfdea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated all_stocks_df with filtered data\n",
      "Shape: (4155893, 17)\n",
      "Date range: 2020-01-01 00:00:25+00:00 to 2022-02-26 23:59:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Update the original dataframe with filtered data\n",
    "all_stocks_df = all_stocks_df_filtered.copy()\n",
    "\n",
    "print(\"Updated all_stocks_df with filtered data\")\n",
    "print(f\"Shape: {all_stocks_df.shape}\")\n",
    "print(f\"Date range: {all_stocks_df['created_at'].min()} to {all_stocks_df['created_at'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "340eeee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting sentiments from AAPL data...\n",
      "\n",
      "Sentiment distribution in all stocks:\n",
      "sentiment\n",
      "Bullish    1617727\n",
      "Bearish     528069\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentiment distribution in all stocks:\n",
      "sentiment\n",
      "Bullish    1617727\n",
      "Bearish     528069\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def extract_sentiment(entities_str):\n",
    "    \"\"\"Extract sentiment from entities column\"\"\"\n",
    "    if pd.isna(entities_str):\n",
    "        return None\n",
    "    try:\n",
    "        # Convert string to dict\n",
    "        entities_dict = ast.literal_eval(str(entities_str))\n",
    "        if 'sentiment' in entities_dict and entities_dict['sentiment'] is not None:\n",
    "            if 'basic' in entities_dict['sentiment']:\n",
    "                return entities_dict['sentiment']['basic']\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "# Apply sentiment extraction \n",
    "print(\"Extracting sentiments from AAPL data...\")\n",
    "all_stocks_df['sentiment'] = all_stocks_df['entities'].apply(extract_sentiment)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nSentiment distribution in all stocks:\")\n",
    "print(all_stocks_df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8fa40279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user</th>\n",
       "      <th>source</th>\n",
       "      <th>symbols</th>\n",
       "      <th>conversation</th>\n",
       "      <th>mentioned_users</th>\n",
       "      <th>entities</th>\n",
       "      <th>likes</th>\n",
       "      <th>reshares</th>\n",
       "      <th>reshare_message</th>\n",
       "      <th>links</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>owned_symbols</th>\n",
       "      <th>structurable</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>264350906</td>\n",
       "      <td>$AAPL sold my AAPL $124 &amp;quot;yesterday of cou...</td>\n",
       "      <td>2020-12-15 14:40:07+00:00</td>\n",
       "      <td>{'id': 410481, 'username': 'Navyman', 'name': ...</td>\n",
       "      <td>{'id': 2269, 'title': 'StockTwits Web', 'url':...</td>\n",
       "      <td>[{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...</td>\n",
       "      <td>{'parent_message_id': 264350906, 'in_reply_to_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'sentiment': None}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>264350850</td>\n",
       "      <td>$AAPL Moving fast early!</td>\n",
       "      <td>2020-12-15 14:40:00+00:00</td>\n",
       "      <td>{'id': 1563546, 'username': 'Trader_Ty', 'name...</td>\n",
       "      <td>{'id': 2269, 'title': 'StockTwits Web', 'url':...</td>\n",
       "      <td>[{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'sentiment': {'basic': 'Bullish'}}</td>\n",
       "      <td>{'total': 3, 'user_ids': [683907, 3602081, 309...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>264350821</td>\n",
       "      <td>$AAPL if confirms daily can rip</td>\n",
       "      <td>2020-12-15 14:39:57+00:00</td>\n",
       "      <td>{'id': 24272, 'username': 'danshep55', 'name':...</td>\n",
       "      <td>{'id': 1149, 'title': 'StockTwits for iOS', 'u...</td>\n",
       "      <td>[{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'sentiment': {'basic': 'Bullish'}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'reshared_count': 1, 'user_ids': [184733]}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>264350809</td>\n",
       "      <td>$AAPL patience pays off</td>\n",
       "      <td>2020-12-15 14:39:55+00:00</td>\n",
       "      <td>{'id': 763412, 'username': 'zeketrades_', 'nam...</td>\n",
       "      <td>{'id': 1149, 'title': 'StockTwits for iOS', 'u...</td>\n",
       "      <td>[{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'sentiment': None}</td>\n",
       "      <td>{'total': 2, 'user_ids': [1703700, 617630]}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>264350762</td>\n",
       "      <td>2020-12-15 14:39:50+00:00 $AAPL, $CMCSA, $SWKS...</td>\n",
       "      <td>2020-12-15 14:39:50+00:00</td>\n",
       "      <td>{'id': 1511377, 'username': 'YuMiStocks_Trade'...</td>\n",
       "      <td>{'id': 5846, 'title': 'ConfluxBot', 'url': 'ht...</td>\n",
       "      <td>[{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'sentiment': None}</td>\n",
       "      <td>{'total': 1, 'user_ids': [4252585]}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id                                               body  \\\n",
       "0           0  264350906  $AAPL sold my AAPL $124 &quot;yesterday of cou...   \n",
       "1           1  264350850                           $AAPL Moving fast early!   \n",
       "2           2  264350821                    $AAPL if confirms daily can rip   \n",
       "3           3  264350809                            $AAPL patience pays off   \n",
       "4           4  264350762  2020-12-15 14:39:50+00:00 $AAPL, $CMCSA, $SWKS...   \n",
       "\n",
       "                 created_at  \\\n",
       "0 2020-12-15 14:40:07+00:00   \n",
       "1 2020-12-15 14:40:00+00:00   \n",
       "2 2020-12-15 14:39:57+00:00   \n",
       "3 2020-12-15 14:39:55+00:00   \n",
       "4 2020-12-15 14:39:50+00:00   \n",
       "\n",
       "                                                user  \\\n",
       "0  {'id': 410481, 'username': 'Navyman', 'name': ...   \n",
       "1  {'id': 1563546, 'username': 'Trader_Ty', 'name...   \n",
       "2  {'id': 24272, 'username': 'danshep55', 'name':...   \n",
       "3  {'id': 763412, 'username': 'zeketrades_', 'nam...   \n",
       "4  {'id': 1511377, 'username': 'YuMiStocks_Trade'...   \n",
       "\n",
       "                                              source  \\\n",
       "0  {'id': 2269, 'title': 'StockTwits Web', 'url':...   \n",
       "1  {'id': 2269, 'title': 'StockTwits Web', 'url':...   \n",
       "2  {'id': 1149, 'title': 'StockTwits for iOS', 'u...   \n",
       "3  {'id': 1149, 'title': 'StockTwits for iOS', 'u...   \n",
       "4  {'id': 5846, 'title': 'ConfluxBot', 'url': 'ht...   \n",
       "\n",
       "                                             symbols  \\\n",
       "0  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
       "1  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
       "2  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
       "3  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
       "4  [{'id': 686, 'symbol': 'AAPL', 'title': 'Apple...   \n",
       "\n",
       "                                        conversation mentioned_users  \\\n",
       "0  {'parent_message_id': 264350906, 'in_reply_to_...              []   \n",
       "1                                                NaN              []   \n",
       "2                                                NaN              []   \n",
       "3                                                NaN              []   \n",
       "4                                                NaN              []   \n",
       "\n",
       "                              entities  \\\n",
       "0                  {'sentiment': None}   \n",
       "1  {'sentiment': {'basic': 'Bullish'}}   \n",
       "2  {'sentiment': {'basic': 'Bullish'}}   \n",
       "3                  {'sentiment': None}   \n",
       "4                  {'sentiment': None}   \n",
       "\n",
       "                                               likes  \\\n",
       "0                                                NaN   \n",
       "1  {'total': 3, 'user_ids': [683907, 3602081, 309...   \n",
       "2                                                NaN   \n",
       "3        {'total': 2, 'user_ids': [1703700, 617630]}   \n",
       "4                {'total': 1, 'user_ids': [4252585]}   \n",
       "\n",
       "                                      reshares reshare_message links  \\\n",
       "0                                          NaN             NaN   NaN   \n",
       "1                                          NaN             NaN   NaN   \n",
       "2  {'reshared_count': 1, 'user_ids': [184733]}             NaN   NaN   \n",
       "3                                          NaN             NaN   NaN   \n",
       "4                                          NaN             NaN   NaN   \n",
       "\n",
       "  stock_name owned_symbols structurable sentiment  \n",
       "0       AAPL           NaN          NaN      None  \n",
       "1       AAPL           NaN          NaN   Bullish  \n",
       "2       AAPL           NaN          NaN   Bullish  \n",
       "3       AAPL           NaN          NaN      None  \n",
       "4       AAPL           NaN          NaN      None  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stocks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "26091228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Sentiment by Date and Stock:\n",
      "sentiment        date stock_name  net_sentiment\n",
      "0          2020-01-01       AAPL       0.560976\n",
      "1          2020-01-01       AMZN       0.956522\n",
      "2          2020-01-01         FB       0.785714\n",
      "3          2020-01-01       NVDA       1.000000\n",
      "4          2020-01-01       TSLA       0.466667\n",
      "5          2020-01-02       AAPL       0.688889\n",
      "6          2020-01-02       AMZN       0.934664\n",
      "7          2020-01-02         FB       0.941748\n",
      "8          2020-01-02       NVDA       1.000000\n",
      "9          2020-01-02       TSLA       0.622887\n",
      "\n",
      "Shape: (3940, 3)\n",
      "\n",
      "Stocks included: ['AAPL' 'AMZN' 'FB' 'NVDA' 'TSLA']\n",
      "\n",
      "Records per stock:\n",
      "stock_name\n",
      "AAPL    788\n",
      "AMZN    788\n",
      "FB      788\n",
      "NVDA    788\n",
      "TSLA    788\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert created_at to datetime\n",
    "all_stocks_df['created_at'] = pd.to_datetime(all_stocks_df['created_at'])\n",
    "\n",
    "# Extract date from created_at\n",
    "all_stocks_df['date'] = all_stocks_df['created_at'].dt.date\n",
    "\n",
    "# Group by both date and stock_name to calculate sentiment counts\n",
    "all_stock_sentiment_daily = all_stocks_df.groupby(['date', 'stock_name'])['sentiment'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Calculate net sentiment\n",
    "if 'Bullish' in all_stock_sentiment_daily.columns and 'Bearish' in all_stock_sentiment_daily.columns:\n",
    "    all_stock_sentiment_daily['net_sentiment'] = (all_stock_sentiment_daily['Bullish'] - all_stock_sentiment_daily['Bearish']) / \\\n",
    "                                             (all_stock_sentiment_daily['Bullish'] + all_stock_sentiment_daily['Bearish'])\n",
    "else:\n",
    "    all_stock_sentiment_daily['net_sentiment'] = 0\n",
    "\n",
    "# Keep only net_sentiment column and reset index to make date and stock_name columns\n",
    "stock_net_sentiment = all_stock_sentiment_daily[['net_sentiment']].reset_index()\n",
    "\n",
    "print(\"Net Sentiment by Date and Stock:\")\n",
    "print(stock_net_sentiment.head(10))\n",
    "print(f\"\\nShape: {stock_net_sentiment.shape}\")\n",
    "print(f\"\\nStocks included: {stock_net_sentiment['stock_name'].unique()}\")\n",
    "print(f\"\\nRecords per stock:\")\n",
    "print(stock_net_sentiment['stock_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a30222bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data shape: (3960, 14)\n",
      "\n",
      "Stocks in merged data:\n",
      "stock_name\n",
      "AAPL    798\n",
      "NVDA    797\n",
      "TSLA    789\n",
      "AMZN    788\n",
      "FB      788\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare all stock price data\n",
    "cols_to_keep = ['Date', 'Stock_name', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "rename_dict = {'Date': 'date', 'Stock_name': 'stock_name'}\n",
    "\n",
    "# Combine all stock prices\n",
    "all_prices = pd.concat([\n",
    "    amzn_ready[cols_to_keep].rename(columns=rename_dict),\n",
    "    aapl_ready[cols_to_keep].rename(columns=rename_dict),\n",
    "    tsla_ready[cols_to_keep].rename(columns=rename_dict),\n",
    "    meta_ready[cols_to_keep].rename(columns=rename_dict),\n",
    "    nvda_ready[cols_to_keep].rename(columns=rename_dict)\n",
    "], ignore_index=True)\n",
    "\n",
    "# Convert date columns to datetime\n",
    "all_prices['date'] = pd.to_datetime(all_prices['date'])\n",
    "stock_net_sentiment['date'] = pd.to_datetime(stock_net_sentiment['date'])\n",
    "\n",
    "# Merge all data\n",
    "merged_df = stock_net_sentiment.merge(sofr_ready, on='date', how='left') \\\n",
    "    .merge(news_ready, on=['date', 'stock_name'], how='left') \\\n",
    "    .merge(unemployment_ready, on='date', how='left') \\\n",
    "    .merge(fed_ready, on='date', how='left') \\\n",
    "    .merge(risk_ready, on='date', how='left') \\\n",
    "    .merge(all_prices, on=['date', 'stock_name'], how='left')\n",
    "\n",
    "print(f\"Merged data shape: {merged_df.shape}\")\n",
    "print(f\"\\nStocks in merged data:\")\n",
    "print(merged_df['stock_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "bde24931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>net_sentiment</th>\n",
       "      <th>sofr_rate</th>\n",
       "      <th>NewsCount</th>\n",
       "      <th>NewsTone</th>\n",
       "      <th>unemployment</th>\n",
       "      <th>Fed_Rate</th>\n",
       "      <th>RiskAppetite</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>268</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>-0.016863</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>FB</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2572</td>\n",
       "      <td>-0.011213</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.010415</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>276</td>\n",
       "      <td>-0.024558</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date stock_name  net_sentiment  sofr_rate  NewsCount  NewsTone  \\\n",
       "0 2020-01-01       AAPL       0.560976        NaN        268  0.003521   \n",
       "1 2020-01-01       AMZN       0.956522        NaN        240 -0.016863   \n",
       "2 2020-01-01         FB       0.785714        NaN       2572 -0.011213   \n",
       "3 2020-01-01       NVDA       1.000000        NaN         16 -0.010415   \n",
       "4 2020-01-01       TSLA       0.466667        NaN        276 -0.024558   \n",
       "\n",
       "   unemployment  Fed_Rate  RiskAppetite Open  High  Low  Close  Volume  \n",
       "0        5869.0      1.75           NaN  NaN   NaN  NaN    NaN     NaN  \n",
       "1        5869.0      1.75           NaN  NaN   NaN  NaN    NaN     NaN  \n",
       "2        5869.0      1.75           NaN  NaN   NaN  NaN    NaN     NaN  \n",
       "3        5869.0      1.75           NaN  NaN   NaN  NaN    NaN     NaN  \n",
       "4        5869.0      1.75           NaN  NaN   NaN  NaN    NaN     NaN  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "063b7a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled missing macro variables\n",
      "Remaining NaN in sofr_rate: 5\n",
      "Remaining NaN in RiskAppetite: 5\n"
     ]
    }
   ],
   "source": [
    "# Forward fill macro variables (they don't change daily)\n",
    "merged_df['Fed_Rate'] = merged_df['Fed_Rate'].ffill()\n",
    "merged_df['sofr_rate'] = merged_df['sofr_rate'].ffill()\n",
    "merged_df['unemployment'] = merged_df['unemployment'].ffill()\n",
    "merged_df['RiskAppetite'] = merged_df['RiskAppetite'].ffill()\n",
    "\n",
    "print(\"Filled missing macro variables\")\n",
    "print(f\"Remaining NaN in sofr_rate: {merged_df['sofr_rate'].isna().sum()}\")\n",
    "print(f\"Remaining NaN in RiskAppetite: {merged_df['RiskAppetite'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "feea074c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backward fill:\n",
      "Remaining NaN in sofr_rate: 0\n",
      "Remaining NaN in RiskAppetite: 0\n",
      "\n",
      "First 10 rows after filling:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>net_sentiment</th>\n",
       "      <th>sofr_rate</th>\n",
       "      <th>NewsCount</th>\n",
       "      <th>NewsTone</th>\n",
       "      <th>unemployment</th>\n",
       "      <th>Fed_Rate</th>\n",
       "      <th>RiskAppetite</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>1.54</td>\n",
       "      <td>268</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.54</td>\n",
       "      <td>240</td>\n",
       "      <td>-0.016863</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>FB</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.54</td>\n",
       "      <td>2572</td>\n",
       "      <td>-0.011213</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.54</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.010415</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.54</td>\n",
       "      <td>276</td>\n",
       "      <td>-0.024558</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>1.54</td>\n",
       "      <td>513</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>74.06</td>\n",
       "      <td>75.15</td>\n",
       "      <td>73.80</td>\n",
       "      <td>75.09</td>\n",
       "      <td>135480400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.934664</td>\n",
       "      <td>1.54</td>\n",
       "      <td>484</td>\n",
       "      <td>-0.005955</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>93.75</td>\n",
       "      <td>94.90</td>\n",
       "      <td>93.21</td>\n",
       "      <td>94.90</td>\n",
       "      <td>80580000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>FB</td>\n",
       "      <td>0.941748</td>\n",
       "      <td>1.54</td>\n",
       "      <td>3709</td>\n",
       "      <td>-0.010479</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>206.75</td>\n",
       "      <td>209.79</td>\n",
       "      <td>206.27</td>\n",
       "      <td>209.78</td>\n",
       "      <td>12077100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.54</td>\n",
       "      <td>18</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>5.97</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.92</td>\n",
       "      <td>6.00</td>\n",
       "      <td>237536000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.622887</td>\n",
       "      <td>1.54</td>\n",
       "      <td>384</td>\n",
       "      <td>-0.015637</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>28.3</td>\n",
       "      <td>28.71</td>\n",
       "      <td>28.11</td>\n",
       "      <td>28.68</td>\n",
       "      <td>142981500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date stock_name  net_sentiment  sofr_rate  NewsCount  NewsTone  \\\n",
       "0 2020-01-01       AAPL       0.560976       1.54        268  0.003521   \n",
       "1 2020-01-01       AMZN       0.956522       1.54        240 -0.016863   \n",
       "2 2020-01-01         FB       0.785714       1.54       2572 -0.011213   \n",
       "3 2020-01-01       NVDA       1.000000       1.54         16 -0.010415   \n",
       "4 2020-01-01       TSLA       0.466667       1.54        276 -0.024558   \n",
       "5 2020-01-02       AAPL       0.688889       1.54        513  0.006356   \n",
       "6 2020-01-02       AMZN       0.934664       1.54        484 -0.005955   \n",
       "7 2020-01-02         FB       0.941748       1.54       3709 -0.010479   \n",
       "8 2020-01-02       NVDA       1.000000       1.54         18  0.001846   \n",
       "9 2020-01-02       TSLA       0.622887       1.54        384 -0.015637   \n",
       "\n",
       "   unemployment  Fed_Rate  RiskAppetite    Open    High     Low   Close  \\\n",
       "0        5869.0      1.75        0.1534     NaN     NaN     NaN     NaN   \n",
       "1        5869.0      1.75        0.1534     NaN     NaN     NaN     NaN   \n",
       "2        5869.0      1.75        0.1534     NaN     NaN     NaN     NaN   \n",
       "3        5869.0      1.75        0.1534     NaN     NaN     NaN     NaN   \n",
       "4        5869.0      1.75        0.1534     NaN     NaN     NaN     NaN   \n",
       "5        5869.0      1.75        0.1534   74.06   75.15   73.80   75.09   \n",
       "6        5869.0      1.75        0.1534   93.75   94.90   93.21   94.90   \n",
       "7        5869.0      1.75        0.1534  206.75  209.79  206.27  209.78   \n",
       "8        5869.0      1.75        0.1534    5.97    6.00    5.92    6.00   \n",
       "9        5869.0      1.75        0.1534    28.3   28.71   28.11   28.68   \n",
       "\n",
       "        Volume  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "5  135480400.0  \n",
       "6   80580000.0  \n",
       "7   12077100.0  \n",
       "8  237536000.0  \n",
       "9  142981500.0  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use backward fill for the first few rows\n",
    "merged_df['sofr_rate'] = merged_df['sofr_rate'].bfill()\n",
    "merged_df['RiskAppetite'] = merged_df['RiskAppetite'].bfill()\n",
    "\n",
    "print(\"After backward fill:\")\n",
    "print(f\"Remaining NaN in sofr_rate: {merged_df['sofr_rate'].isna().sum()}\")\n",
    "print(f\"Remaining NaN in RiskAppetite: {merged_df['RiskAppetite'].isna().sum()}\")\n",
    "\n",
    "# Check the first few rows\n",
    "print(\"\\nFirst 10 rows after filling:\")\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9bbba15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOMC dummy variable added\n",
      "Total FOMC meeting days in dataset: 160\n",
      "\n",
      "FOMC distribution:\n",
      "FOMC\n",
      "0    3800\n",
      "1     160\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of FOMC meeting dates in the data:\n",
      "           date stock_name  FOMC\n",
      "135  2020-01-28       AAPL     1\n",
      "140  2020-01-29       AAPL     1\n",
      "592  2020-04-28       AAPL     1\n",
      "597  2020-04-29       AAPL     1\n",
      "804  2020-06-09       AAPL     1\n",
      "809  2020-06-10       AAPL     1\n",
      "1049 2020-07-28       AAPL     1\n",
      "1054 2020-07-29       AAPL     1\n",
      "1298 2020-09-15       AAPL     1\n",
      "1303 2020-09-16       AAPL     1\n"
     ]
    }
   ],
   "source": [
    "# Add FOMC dummy variable\n",
    "# FOMC = 1 if the date is an FOMC meeting date (or day 2), 0 otherwise\n",
    "merged_df['FOMC'] = merged_df['date'].isin(fomc_date_set).astype(int)\n",
    "\n",
    "print(f\"FOMC dummy variable added\")\n",
    "print(f\"Total FOMC meeting days in dataset: {merged_df['FOMC'].sum()}\")\n",
    "print(f\"\\nFOMC distribution:\")\n",
    "print(merged_df['FOMC'].value_counts())\n",
    "\n",
    "# Show some FOMC dates\n",
    "print(f\"\\nSample of FOMC meeting dates in the data:\")\n",
    "fomc_rows = merged_df[merged_df['FOMC'] == 1][['date', 'stock_name', 'FOMC']].drop_duplicates(subset='date').head(10)\n",
    "print(fomc_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "18cde1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN count in price-related columns:\n",
      "============================================================\n",
      "Open      : 1225 / 3960 (30.93%)\n",
      "High      : 1245 / 3960 (31.44%)\n",
      "Low       : 1245 / 3960 (31.44%)\n",
      "Close     : 1245 / 3960 (31.44%)\n",
      "Volume    : 1245 / 3960 (31.44%)\n",
      "\n",
      "============================================================\n",
      "NaN distribution by stock:\n",
      "============================================================\n",
      "AAPL : 255 /  798 (31.95%) rows with NaN in Close price\n",
      "AMZN : 245 /  788 (31.09%) rows with NaN in Close price\n",
      "FB   : 245 /  788 (31.09%) rows with NaN in Close price\n",
      "NVDA : 254 /  797 (31.87%) rows with NaN in Close price\n",
      "TSLA : 246 /  789 (31.18%) rows with NaN in Close price\n",
      "\n",
      "============================================================\n",
      "Sample of rows with NaN in Close price:\n",
      "============================================================\n",
      "         date stock_name Open  Close  Volume\n",
      "0  2020-01-01       AAPL  NaN    NaN     NaN\n",
      "1  2020-01-01       AMZN  NaN    NaN     NaN\n",
      "2  2020-01-01         FB  NaN    NaN     NaN\n",
      "3  2020-01-01       NVDA  NaN    NaN     NaN\n",
      "4  2020-01-01       TSLA  NaN    NaN     NaN\n",
      "15 2020-01-04       AAPL  NaN    NaN     NaN\n",
      "16 2020-01-04       AMZN  NaN    NaN     NaN\n",
      "17 2020-01-04         FB  NaN    NaN     NaN\n",
      "18 2020-01-04       NVDA  NaN    NaN     NaN\n",
      "19 2020-01-04       TSLA  NaN    NaN     NaN\n",
      "20 2020-01-05       AAPL  NaN    NaN     NaN\n",
      "21 2020-01-05       AMZN  NaN    NaN     NaN\n",
      "22 2020-01-05         FB  NaN    NaN     NaN\n",
      "23 2020-01-05       NVDA  NaN    NaN     NaN\n",
      "24 2020-01-05       TSLA  NaN    NaN     NaN\n",
      "50 2020-01-11       AAPL  NaN    NaN     NaN\n",
      "51 2020-01-11       AMZN  NaN    NaN     NaN\n",
      "52 2020-01-11         FB  NaN    NaN     NaN\n",
      "53 2020-01-11       NVDA  NaN    NaN     NaN\n",
      "54 2020-01-11       TSLA  NaN    NaN     NaN\n",
      "AAPL : 255 /  798 (31.95%) rows with NaN in Close price\n",
      "AMZN : 245 /  788 (31.09%) rows with NaN in Close price\n",
      "FB   : 245 /  788 (31.09%) rows with NaN in Close price\n",
      "NVDA : 254 /  797 (31.87%) rows with NaN in Close price\n",
      "TSLA : 246 /  789 (31.18%) rows with NaN in Close price\n",
      "\n",
      "============================================================\n",
      "Sample of rows with NaN in Close price:\n",
      "============================================================\n",
      "         date stock_name Open  Close  Volume\n",
      "0  2020-01-01       AAPL  NaN    NaN     NaN\n",
      "1  2020-01-01       AMZN  NaN    NaN     NaN\n",
      "2  2020-01-01         FB  NaN    NaN     NaN\n",
      "3  2020-01-01       NVDA  NaN    NaN     NaN\n",
      "4  2020-01-01       TSLA  NaN    NaN     NaN\n",
      "15 2020-01-04       AAPL  NaN    NaN     NaN\n",
      "16 2020-01-04       AMZN  NaN    NaN     NaN\n",
      "17 2020-01-04         FB  NaN    NaN     NaN\n",
      "18 2020-01-04       NVDA  NaN    NaN     NaN\n",
      "19 2020-01-04       TSLA  NaN    NaN     NaN\n",
      "20 2020-01-05       AAPL  NaN    NaN     NaN\n",
      "21 2020-01-05       AMZN  NaN    NaN     NaN\n",
      "22 2020-01-05         FB  NaN    NaN     NaN\n",
      "23 2020-01-05       NVDA  NaN    NaN     NaN\n",
      "24 2020-01-05       TSLA  NaN    NaN     NaN\n",
      "50 2020-01-11       AAPL  NaN    NaN     NaN\n",
      "51 2020-01-11       AMZN  NaN    NaN     NaN\n",
      "52 2020-01-11         FB  NaN    NaN     NaN\n",
      "53 2020-01-11       NVDA  NaN    NaN     NaN\n",
      "54 2020-01-11       TSLA  NaN    NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "# Check NaN distribution in price columns\n",
    "print(\"NaN count in price-related columns:\")\n",
    "print(\"=\"*60)\n",
    "price_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "for col in price_cols:\n",
    "    nan_count = merged_df[col].isna().sum()\n",
    "    total = len(merged_df)\n",
    "    pct = (nan_count / total) * 100\n",
    "    print(f\"{col:10s}: {nan_count:4d} / {total} ({pct:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NaN distribution by stock:\")\n",
    "print(\"=\"*60)\n",
    "for stock in merged_df['stock_name'].unique():\n",
    "    stock_data = merged_df[merged_df['stock_name'] == stock]\n",
    "    nan_count = stock_data['Close'].isna().sum()\n",
    "    total = len(stock_data)\n",
    "    pct = (nan_count / total) * 100\n",
    "    print(f\"{stock:5s}: {nan_count:3d} / {total:4d} ({pct:.2f}%) rows with NaN in Close price\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Sample of rows with NaN in Close price:\")\n",
    "print(\"=\"*60)\n",
    "print(merged_df[merged_df['Close'].isna()][['date', 'stock_name', 'Open', 'Close', 'Volume']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8fbfa766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning completed.\n",
      "Final dimensions: (2705, 22)\n",
      "\n",
      "Key columns preview (Check if Monday has data):\n",
      "                       Log_Volume  Log_Return  Return_Abs_Lag1  \\\n",
      "stock_name date                                                  \n",
      "AAPL       2020-01-06   18.589471    0.007903         0.009769   \n",
      "           2020-01-07   18.505683   -0.004681         0.007903   \n",
      "           2020-01-08   18.698912    0.015958         0.004681   \n",
      "           2020-01-09   18.951946    0.021018         0.015958   \n",
      "           2020-01-10   18.761748    0.002194         0.021018   \n",
      "           2020-01-13   18.615688    0.021172         0.002194   \n",
      "           2020-01-14   18.902825   -0.013595         0.021172   \n",
      "           2020-01-15   18.618905   -0.004359         0.013595   \n",
      "           2020-01-16   18.505290    0.012513         0.004359   \n",
      "           2020-01-17   18.741433    0.010979         0.012513   \n",
      "\n",
      "                       Volatility_Lag1  \n",
      "stock_name date                         \n",
      "AAPL       2020-01-06         0.013595  \n",
      "           2020-01-07         0.024506  \n",
      "           2020-01-08         0.011339  \n",
      "           2020-01-09         0.024499  \n",
      "           2020-01-10         0.013800  \n",
      "           2020-01-13         0.014295  \n",
      "           2020-01-14         0.018996  \n",
      "           2020-01-15         0.017050  \n",
      "           2020-01-16         0.019112  \n",
      "           2020-01-17         0.011607  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = merged_df.copy()\n",
    "\n",
    "\n",
    "# 2. Time series basic processing\n",
    "# Convert to datetime and sort (critical for ffill and shift operations)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(by=['stock_name', 'date'])\n",
    "\n",
    "# 3. Fill missing macro data\n",
    "# Logic: Macro variables (unemployment/interest rates) don't change daily, use forward fill\n",
    "# macro_cols = ['unemployment', 'sofr_rate', 'RiskAppetite', 'Fed_Rate']\n",
    "# df[macro_cols] = df[macro_cols].ffill().bfill()\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. [KEY FIX] Clean data types and remove non-trading days first\n",
    "# ==============================================================================\n",
    "\n",
    "# A. Force conversion to numeric (handle possible strings or commas)\n",
    "cols_to_numeric = ['Open', 'High', 'Low', 'Close', 'Volume', 'NewsCount', 'net_sentiment']\n",
    "for col in cols_to_numeric:\n",
    "    # errors='coerce' converts invalid values to NaN\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# B. [CORE FIX] Remove weekends and holidays (rows with missing Volume or Close_Price)\n",
    "# This MUST happen before calculating returns and lags!\n",
    "# This way, \"Monday's\" previous row is \"Friday\", so Log_Return won't be NaN\n",
    "df = df.dropna(subset=['Volume', 'Close', 'Open', 'High', 'Low'])\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. Feature Engineering - shift(1) now represents \"previous trading day\"\n",
    "# ==============================================================================\n",
    "\n",
    "# A. Trading volume (Log Volume) - Dependent variable\n",
    "df['Log_Volume'] = np.log(df['Volume'] + 1)\n",
    "\n",
    "# B. Volatility indicator (Intraday Volatility)\n",
    "# Logic: (High - Low) / Open\n",
    "df['Intraday_Range'] = (df['High'] - df['Low']) / (df['Open'] + 1e-8)\n",
    "\n",
    "# C. Stock return (Log Return)\n",
    "# Logic: ln(today's close / previous trading day's close)\n",
    "# Note: Use shift() directly since weekends have been removed\n",
    "df['Close_Lag1'] = df.groupby('stock_name')['Close'].shift(1)\n",
    "df['Log_Return'] = np.log(df['Close'] / df['Close_Lag1'])\n",
    "\n",
    "# D. Attention/Buzz (Log Buzz)\n",
    "df['Log_Buzz'] = np.log(df['NewsCount'] + 1)\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. Lagging Operations - Predictor variables\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Yesterday's sentiment -> predict today's volume\n",
    "df['Sentiment_Lag1'] = df.groupby('stock_name')['net_sentiment'].shift(1)\n",
    "\n",
    "# 2. Yesterday's buzz -> predict today's volume\n",
    "df['Log_Buzz_Lag1']  = df.groupby('stock_name')['Log_Buzz'].shift(1)\n",
    "\n",
    "# 3. Yesterday's volatility -> predict today's volume\n",
    "df['Volatility_Lag1'] = df.groupby('stock_name')['Intraday_Range'].shift(1)\n",
    "\n",
    "# 4. Yesterday's absolute return -> predict today's volume\n",
    "df['Return_Abs_Lag1'] = df.groupby('stock_name')['Log_Return'].shift(1).abs()\n",
    "\n",
    "# ==============================================================================\n",
    "# 7. Final cleanup and indexing\n",
    "# ==============================================================================\n",
    "\n",
    "# Remove first row for each stock due to lag calculations\n",
    "df_final = df.dropna(subset=['Sentiment_Lag1', 'Volatility_Lag1', 'Return_Abs_Lag1'])\n",
    "\n",
    "# Set panel index\n",
    "df_final = df_final.set_index(['stock_name', 'date'])\n",
    "\n",
    "# Check results\n",
    "print(\"Data cleaning completed.\")\n",
    "print(f\"Final dimensions: {df_final.shape}\")\n",
    "print(f\"\\nKey columns preview (Check if Monday has data):\")\n",
    "# Check if Log_Return has NaN values\n",
    "print(df_final[['Log_Volume', 'Log_Return', 'Return_Abs_Lag1', 'Volatility_Lag1']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6d5bae33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>net_sentiment</th>\n",
       "      <th>sofr_rate</th>\n",
       "      <th>NewsCount</th>\n",
       "      <th>NewsTone</th>\n",
       "      <th>unemployment</th>\n",
       "      <th>Fed_Rate</th>\n",
       "      <th>RiskAppetite</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>...</th>\n",
       "      <th>FOMC</th>\n",
       "      <th>Log_Volume</th>\n",
       "      <th>Intraday_Range</th>\n",
       "      <th>Close_Lag1</th>\n",
       "      <th>Log_Return</th>\n",
       "      <th>Log_Buzz</th>\n",
       "      <th>Sentiment_Lag1</th>\n",
       "      <th>Log_Buzz_Lag1</th>\n",
       "      <th>Volatility_Lag1</th>\n",
       "      <th>Return_Abs_Lag1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock_name</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">AAPL</th>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>0.400531</td>\n",
       "      <td>1.55</td>\n",
       "      <td>539</td>\n",
       "      <td>0.007840</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>73.45</td>\n",
       "      <td>74.99</td>\n",
       "      <td>73.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.589471</td>\n",
       "      <td>0.024506</td>\n",
       "      <td>74.36</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>6.291569</td>\n",
       "      <td>0.283163</td>\n",
       "      <td>6.598509</td>\n",
       "      <td>0.013595</td>\n",
       "      <td>0.009769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>0.297158</td>\n",
       "      <td>1.56</td>\n",
       "      <td>497</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>74.96</td>\n",
       "      <td>75.22</td>\n",
       "      <td>74.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.505683</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>74.95</td>\n",
       "      <td>-0.004681</td>\n",
       "      <td>6.210600</td>\n",
       "      <td>0.400531</td>\n",
       "      <td>6.291569</td>\n",
       "      <td>0.024506</td>\n",
       "      <td>0.007903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>0.598662</td>\n",
       "      <td>1.55</td>\n",
       "      <td>776</td>\n",
       "      <td>-0.001556</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>74.29</td>\n",
       "      <td>76.11</td>\n",
       "      <td>74.29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.698912</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>74.60</td>\n",
       "      <td>0.015958</td>\n",
       "      <td>6.655440</td>\n",
       "      <td>0.297158</td>\n",
       "      <td>6.210600</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>0.004681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-09</th>\n",
       "      <td>0.629080</td>\n",
       "      <td>1.55</td>\n",
       "      <td>675</td>\n",
       "      <td>-0.000771</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>76.81</td>\n",
       "      <td>77.61</td>\n",
       "      <td>76.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.951946</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>75.80</td>\n",
       "      <td>0.021018</td>\n",
       "      <td>6.516193</td>\n",
       "      <td>0.598662</td>\n",
       "      <td>6.655440</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>0.015958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-10</th>\n",
       "      <td>0.449378</td>\n",
       "      <td>1.55</td>\n",
       "      <td>563</td>\n",
       "      <td>-0.001866</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>77.65</td>\n",
       "      <td>78.17</td>\n",
       "      <td>77.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.761748</td>\n",
       "      <td>0.014295</td>\n",
       "      <td>77.41</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>6.335054</td>\n",
       "      <td>0.629080</td>\n",
       "      <td>6.516193</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.021018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-13</th>\n",
       "      <td>0.564202</td>\n",
       "      <td>1.54</td>\n",
       "      <td>659</td>\n",
       "      <td>-0.002693</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>77.91</td>\n",
       "      <td>79.27</td>\n",
       "      <td>77.79</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.615688</td>\n",
       "      <td>0.018996</td>\n",
       "      <td>77.58</td>\n",
       "      <td>0.021172</td>\n",
       "      <td>6.492240</td>\n",
       "      <td>0.449378</td>\n",
       "      <td>6.335054</td>\n",
       "      <td>0.014295</td>\n",
       "      <td>0.002194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-14</th>\n",
       "      <td>0.378582</td>\n",
       "      <td>1.55</td>\n",
       "      <td>843</td>\n",
       "      <td>-0.009979</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>79.18</td>\n",
       "      <td>79.39</td>\n",
       "      <td>78.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.902825</td>\n",
       "      <td>0.017050</td>\n",
       "      <td>79.24</td>\n",
       "      <td>-0.013595</td>\n",
       "      <td>6.738152</td>\n",
       "      <td>0.564202</td>\n",
       "      <td>6.492240</td>\n",
       "      <td>0.018996</td>\n",
       "      <td>0.021172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-15</th>\n",
       "      <td>0.326087</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1074</td>\n",
       "      <td>-0.016315</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>77.96</td>\n",
       "      <td>78.88</td>\n",
       "      <td>77.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.618905</td>\n",
       "      <td>0.019112</td>\n",
       "      <td>78.17</td>\n",
       "      <td>-0.004359</td>\n",
       "      <td>6.980076</td>\n",
       "      <td>0.378582</td>\n",
       "      <td>6.738152</td>\n",
       "      <td>0.017050</td>\n",
       "      <td>0.013595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-16</th>\n",
       "      <td>0.467085</td>\n",
       "      <td>1.55</td>\n",
       "      <td>925</td>\n",
       "      <td>-0.002942</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>78.40</td>\n",
       "      <td>78.93</td>\n",
       "      <td>78.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.505290</td>\n",
       "      <td>0.011607</td>\n",
       "      <td>77.83</td>\n",
       "      <td>0.012513</td>\n",
       "      <td>6.830874</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>6.980076</td>\n",
       "      <td>0.019112</td>\n",
       "      <td>0.004359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-17</th>\n",
       "      <td>0.673820</td>\n",
       "      <td>1.54</td>\n",
       "      <td>886</td>\n",
       "      <td>-0.000481</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>79.07</td>\n",
       "      <td>79.68</td>\n",
       "      <td>78.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.741433</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>78.81</td>\n",
       "      <td>0.010979</td>\n",
       "      <td>6.787845</td>\n",
       "      <td>0.467085</td>\n",
       "      <td>6.830874</td>\n",
       "      <td>0.011607</td>\n",
       "      <td>0.012513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-21</th>\n",
       "      <td>0.604396</td>\n",
       "      <td>1.54</td>\n",
       "      <td>768</td>\n",
       "      <td>-0.004543</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>79.30</td>\n",
       "      <td>79.75</td>\n",
       "      <td>79.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.523627</td>\n",
       "      <td>0.009458</td>\n",
       "      <td>79.68</td>\n",
       "      <td>-0.006800</td>\n",
       "      <td>6.645091</td>\n",
       "      <td>0.673820</td>\n",
       "      <td>6.787845</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>0.010979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-22</th>\n",
       "      <td>0.724928</td>\n",
       "      <td>1.54</td>\n",
       "      <td>995</td>\n",
       "      <td>-0.005106</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>79.64</td>\n",
       "      <td>80.00</td>\n",
       "      <td>79.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.438839</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>79.14</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>6.903747</td>\n",
       "      <td>0.604396</td>\n",
       "      <td>6.645091</td>\n",
       "      <td>0.009458</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-23</th>\n",
       "      <td>0.722846</td>\n",
       "      <td>1.54</td>\n",
       "      <td>914</td>\n",
       "      <td>-0.006753</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>79.48</td>\n",
       "      <td>79.89</td>\n",
       "      <td>78.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.464430</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>79.43</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>6.818924</td>\n",
       "      <td>0.724928</td>\n",
       "      <td>6.903747</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>0.003658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-24</th>\n",
       "      <td>0.468822</td>\n",
       "      <td>1.53</td>\n",
       "      <td>837</td>\n",
       "      <td>-0.007355</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>80.06</td>\n",
       "      <td>80.83</td>\n",
       "      <td>79.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.802793</td>\n",
       "      <td>0.018111</td>\n",
       "      <td>79.81</td>\n",
       "      <td>-0.002886</td>\n",
       "      <td>6.731018</td>\n",
       "      <td>0.722846</td>\n",
       "      <td>6.818924</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>0.004773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-27</th>\n",
       "      <td>0.465385</td>\n",
       "      <td>1.53</td>\n",
       "      <td>654</td>\n",
       "      <td>-0.000321</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>77.51</td>\n",
       "      <td>77.94</td>\n",
       "      <td>76.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.902736</td>\n",
       "      <td>0.022191</td>\n",
       "      <td>79.58</td>\n",
       "      <td>-0.029845</td>\n",
       "      <td>6.484635</td>\n",
       "      <td>0.468822</td>\n",
       "      <td>6.731018</td>\n",
       "      <td>0.018111</td>\n",
       "      <td>0.002886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-28</th>\n",
       "      <td>0.477644</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1223</td>\n",
       "      <td>-0.002085</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>78.15</td>\n",
       "      <td>79.60</td>\n",
       "      <td>78.05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.904550</td>\n",
       "      <td>0.019834</td>\n",
       "      <td>77.24</td>\n",
       "      <td>0.027833</td>\n",
       "      <td>7.109879</td>\n",
       "      <td>0.465385</td>\n",
       "      <td>6.484635</td>\n",
       "      <td>0.022191</td>\n",
       "      <td>0.029845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-29</th>\n",
       "      <td>0.544103</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1969</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>81.11</td>\n",
       "      <td>81.96</td>\n",
       "      <td>80.35</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>19.191850</td>\n",
       "      <td>0.019850</td>\n",
       "      <td>79.42</td>\n",
       "      <td>0.020686</td>\n",
       "      <td>7.585789</td>\n",
       "      <td>0.477644</td>\n",
       "      <td>7.109879</td>\n",
       "      <td>0.019834</td>\n",
       "      <td>0.027833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-30</th>\n",
       "      <td>0.367483</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1416</td>\n",
       "      <td>-0.004703</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-0.0488</td>\n",
       "      <td>80.14</td>\n",
       "      <td>81.02</td>\n",
       "      <td>79.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.657674</td>\n",
       "      <td>0.016596</td>\n",
       "      <td>81.08</td>\n",
       "      <td>-0.001358</td>\n",
       "      <td>7.256297</td>\n",
       "      <td>0.544103</td>\n",
       "      <td>7.585789</td>\n",
       "      <td>0.019850</td>\n",
       "      <td>0.020686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>0.206107</td>\n",
       "      <td>1.60</td>\n",
       "      <td>870</td>\n",
       "      <td>-0.001943</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-0.0488</td>\n",
       "      <td>80.23</td>\n",
       "      <td>80.67</td>\n",
       "      <td>77.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19.111768</td>\n",
       "      <td>0.044871</td>\n",
       "      <td>80.97</td>\n",
       "      <td>-0.045350</td>\n",
       "      <td>6.769642</td>\n",
       "      <td>0.367483</td>\n",
       "      <td>7.256297</td>\n",
       "      <td>0.016596</td>\n",
       "      <td>0.001358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-03</th>\n",
       "      <td>0.151408</td>\n",
       "      <td>1.59</td>\n",
       "      <td>762</td>\n",
       "      <td>-0.005529</td>\n",
       "      <td>5753.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-0.0488</td>\n",
       "      <td>76.07</td>\n",
       "      <td>78.37</td>\n",
       "      <td>75.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.973349</td>\n",
       "      <td>0.036940</td>\n",
       "      <td>77.38</td>\n",
       "      <td>-0.002718</td>\n",
       "      <td>6.637258</td>\n",
       "      <td>0.206107</td>\n",
       "      <td>6.769642</td>\n",
       "      <td>0.044871</td>\n",
       "      <td>0.045350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       net_sentiment  sofr_rate  NewsCount  NewsTone  \\\n",
       "stock_name date                                                        \n",
       "AAPL       2020-01-06       0.400531       1.55        539  0.007840   \n",
       "           2020-01-07       0.297158       1.56        497  0.001657   \n",
       "           2020-01-08       0.598662       1.55        776 -0.001556   \n",
       "           2020-01-09       0.629080       1.55        675 -0.000771   \n",
       "           2020-01-10       0.449378       1.55        563 -0.001866   \n",
       "           2020-01-13       0.564202       1.54        659 -0.002693   \n",
       "           2020-01-14       0.378582       1.55        843 -0.009979   \n",
       "           2020-01-15       0.326087       1.56       1074 -0.016315   \n",
       "           2020-01-16       0.467085       1.55        925 -0.002942   \n",
       "           2020-01-17       0.673820       1.54        886 -0.000481   \n",
       "           2020-01-21       0.604396       1.54        768 -0.004543   \n",
       "           2020-01-22       0.724928       1.54        995 -0.005106   \n",
       "           2020-01-23       0.722846       1.54        914 -0.006753   \n",
       "           2020-01-24       0.468822       1.53        837 -0.007355   \n",
       "           2020-01-27       0.465385       1.53        654 -0.000321   \n",
       "           2020-01-28       0.477644       1.53       1223 -0.002085   \n",
       "           2020-01-29       0.544103       1.53       1969  0.001664   \n",
       "           2020-01-30       0.367483       1.58       1416 -0.004703   \n",
       "           2020-01-31       0.206107       1.60        870 -0.001943   \n",
       "           2020-02-03       0.151408       1.59        762 -0.005529   \n",
       "\n",
       "                       unemployment  Fed_Rate  RiskAppetite   Open   High  \\\n",
       "stock_name date                                                             \n",
       "AAPL       2020-01-06        5869.0      1.75        0.1534  73.45  74.99   \n",
       "           2020-01-07        5869.0      1.75        0.1534  74.96  75.22   \n",
       "           2020-01-08        5869.0      1.75        0.1534  74.29  76.11   \n",
       "           2020-01-09        5869.0      1.75        0.0318  76.81  77.61   \n",
       "           2020-01-10        5869.0      1.75        0.0318  77.65  78.17   \n",
       "           2020-01-13        5869.0      1.75        0.0318  77.91  79.27   \n",
       "           2020-01-14        5869.0      1.75        0.0318  79.18  79.39   \n",
       "           2020-01-15        5869.0      1.75        0.0318  77.96  78.88   \n",
       "           2020-01-16        5869.0      1.75        0.1432  78.40  78.93   \n",
       "           2020-01-17        5869.0      1.75        0.1432  79.07  79.68   \n",
       "           2020-01-21        5869.0      1.75        0.1432  79.30  79.75   \n",
       "           2020-01-22        5869.0      1.75        0.1432  79.64  80.00   \n",
       "           2020-01-23        5869.0      1.75        0.2083  79.48  79.89   \n",
       "           2020-01-24        5869.0      1.75        0.2083  80.06  80.83   \n",
       "           2020-01-27        5869.0      1.75        0.2083  77.51  77.94   \n",
       "           2020-01-28        5869.0      1.75        0.2083  78.15  79.60   \n",
       "           2020-01-29        5869.0      1.75        0.2083  81.11  81.96   \n",
       "           2020-01-30        5869.0      1.75       -0.0488  80.14  81.02   \n",
       "           2020-01-31        5869.0      1.75       -0.0488  80.23  80.67   \n",
       "           2020-02-03        5753.0      1.75       -0.0488  76.07  78.37   \n",
       "\n",
       "                         Low  ...  FOMC  Log_Volume  Intraday_Range  \\\n",
       "stock_name date               ...                                     \n",
       "AAPL       2020-01-06  73.19  ...     0   18.589471        0.024506   \n",
       "           2020-01-07  74.37  ...     0   18.505683        0.011339   \n",
       "           2020-01-08  74.29  ...     0   18.698912        0.024499   \n",
       "           2020-01-09  76.55  ...     0   18.951946        0.013800   \n",
       "           2020-01-10  77.06  ...     0   18.761748        0.014295   \n",
       "           2020-01-13  77.79  ...     0   18.615688        0.018996   \n",
       "           2020-01-14  78.04  ...     0   18.902825        0.017050   \n",
       "           2020-01-15  77.39  ...     0   18.618905        0.019112   \n",
       "           2020-01-16  78.02  ...     0   18.505290        0.011607   \n",
       "           2020-01-17  78.75  ...     0   18.741433        0.011762   \n",
       "           2020-01-21  79.00  ...     0   18.523627        0.009458   \n",
       "           2020-01-22  79.33  ...     0   18.438839        0.008413   \n",
       "           2020-01-23  78.91  ...     0   18.464430        0.012330   \n",
       "           2020-01-24  79.38  ...     0   18.802793        0.018111   \n",
       "           2020-01-27  76.22  ...     0   18.902736        0.022191   \n",
       "           2020-01-28  78.05  ...     1   18.904550        0.019834   \n",
       "           2020-01-29  80.35  ...     1   19.191850        0.019850   \n",
       "           2020-01-30  79.69  ...     0   18.657674        0.016596   \n",
       "           2020-01-31  77.07  ...     0   19.111768        0.044871   \n",
       "           2020-02-03  75.56  ...     0   18.973349        0.036940   \n",
       "\n",
       "                       Close_Lag1  Log_Return  Log_Buzz  Sentiment_Lag1  \\\n",
       "stock_name date                                                           \n",
       "AAPL       2020-01-06       74.36    0.007903  6.291569        0.283163   \n",
       "           2020-01-07       74.95   -0.004681  6.210600        0.400531   \n",
       "           2020-01-08       74.60    0.015958  6.655440        0.297158   \n",
       "           2020-01-09       75.80    0.021018  6.516193        0.598662   \n",
       "           2020-01-10       77.41    0.002194  6.335054        0.629080   \n",
       "           2020-01-13       77.58    0.021172  6.492240        0.449378   \n",
       "           2020-01-14       79.24   -0.013595  6.738152        0.564202   \n",
       "           2020-01-15       78.17   -0.004359  6.980076        0.378582   \n",
       "           2020-01-16       77.83    0.012513  6.830874        0.326087   \n",
       "           2020-01-17       78.81    0.010979  6.787845        0.467085   \n",
       "           2020-01-21       79.68   -0.006800  6.645091        0.673820   \n",
       "           2020-01-22       79.14    0.003658  6.903747        0.604396   \n",
       "           2020-01-23       79.43    0.004773  6.818924        0.724928   \n",
       "           2020-01-24       79.81   -0.002886  6.731018        0.722846   \n",
       "           2020-01-27       79.58   -0.029845  6.484635        0.468822   \n",
       "           2020-01-28       77.24    0.027833  7.109879        0.465385   \n",
       "           2020-01-29       79.42    0.020686  7.585789        0.477644   \n",
       "           2020-01-30       81.08   -0.001358  7.256297        0.544103   \n",
       "           2020-01-31       80.97   -0.045350  6.769642        0.367483   \n",
       "           2020-02-03       77.38   -0.002718  6.637258        0.206107   \n",
       "\n",
       "                       Log_Buzz_Lag1  Volatility_Lag1  Return_Abs_Lag1  \n",
       "stock_name date                                                         \n",
       "AAPL       2020-01-06       6.598509         0.013595         0.009769  \n",
       "           2020-01-07       6.291569         0.024506         0.007903  \n",
       "           2020-01-08       6.210600         0.011339         0.004681  \n",
       "           2020-01-09       6.655440         0.024499         0.015958  \n",
       "           2020-01-10       6.516193         0.013800         0.021018  \n",
       "           2020-01-13       6.335054         0.014295         0.002194  \n",
       "           2020-01-14       6.492240         0.018996         0.021172  \n",
       "           2020-01-15       6.738152         0.017050         0.013595  \n",
       "           2020-01-16       6.980076         0.019112         0.004359  \n",
       "           2020-01-17       6.830874         0.011607         0.012513  \n",
       "           2020-01-21       6.787845         0.011762         0.010979  \n",
       "           2020-01-22       6.645091         0.009458         0.006800  \n",
       "           2020-01-23       6.903747         0.008413         0.003658  \n",
       "           2020-01-24       6.818924         0.012330         0.004773  \n",
       "           2020-01-27       6.731018         0.018111         0.002886  \n",
       "           2020-01-28       6.484635         0.022191         0.029845  \n",
       "           2020-01-29       7.109879         0.019834         0.027833  \n",
       "           2020-01-30       7.585789         0.019850         0.020686  \n",
       "           2020-01-31       7.256297         0.016596         0.001358  \n",
       "           2020-02-03       6.769642         0.044871         0.045350  \n",
       "\n",
       "[20 rows x 22 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "354abdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Data Distribution by Stock\n",
      "================================================================================\n",
      "\n",
      "1. Number of observations per stock:\n",
      "------------------------------------------------------------\n",
      "stock_name\n",
      "AAPL    541\n",
      "AMZN    541\n",
      "FB      541\n",
      "NVDA    541\n",
      "TSLA    541\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total observations: 2705\n",
      "\n",
      "================================================================================\n",
      "2. Date range for each stock:\n",
      "------------------------------------------------------------\n",
      "AAPL : 2020-01-06 to 2022-02-25 (541 trading days)\n",
      "AMZN : 2020-01-06 to 2022-02-25 (541 trading days)\n",
      "FB   : 2020-01-06 to 2022-02-25 (541 trading days)\n",
      "NVDA : 2020-01-06 to 2022-02-25 (541 trading days)\n",
      "TSLA : 2020-01-06 to 2022-02-25 (541 trading days)\n",
      "\n",
      "================================================================================\n",
      "3. Descriptive Statistics by Stock:\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Stock: AAPL\n",
      "================================================================================\n",
      "       Log_Volume  net_sentiment  Log_Return  Intraday_Range  NewsCount\n",
      "count    541.0000       541.0000    541.0000        541.0000   541.0000\n",
      "mean      18.5197         0.4797      0.0015          0.0250   821.5749\n",
      "std        0.4313         0.2855      0.0233          0.0146   379.5345\n",
      "min       17.5291        -0.4370     -0.1377          0.0076    72.0000\n",
      "25%       18.2082         0.3070     -0.0091          0.0152   600.0000\n",
      "50%       18.4755         0.5357      0.0010          0.0209   737.0000\n",
      "75%       18.7849         0.7016      0.0140          0.0303   920.0000\n",
      "max       19.8711         0.9325      0.1131          0.1067  3910.0000\n",
      "\n",
      "================================================================================\n",
      "Stock: AMZN\n",
      "================================================================================\n",
      "       Log_Volume  net_sentiment  Log_Return  Intraday_Range  NewsCount\n",
      "count    541.0000       541.0000    541.0000        541.0000   541.0000\n",
      "mean      18.1585         0.6077      0.0009          0.0249   705.0702\n",
      "std        0.3838         0.2001      0.0214          0.0134   316.9192\n",
      "min       17.1841        -0.2105     -0.0825          0.0066    55.0000\n",
      "25%       17.8859         0.4941     -0.0100          0.0155   525.0000\n",
      "50%       18.1059         0.6527      0.0013          0.0216   652.0000\n",
      "75%       18.4079         0.7531      0.0116          0.0306   813.0000\n",
      "max       19.5564         0.9374      0.1269          0.0950  3571.0000\n",
      "\n",
      "================================================================================\n",
      "Stock: FB\n",
      "================================================================================\n",
      "       Log_Volume  net_sentiment  Log_Return  Intraday_Range   NewsCount\n",
      "count    541.0000       541.0000    541.0000        541.0000    541.0000\n",
      "mean      16.7962         0.5502      0.0000          0.0285   4540.3734\n",
      "std        0.4439         0.2342      0.0278          0.0146   1093.1886\n",
      "min       15.7179        -0.3768     -0.3064          0.0066    469.0000\n",
      "25%       16.4961         0.4119     -0.0122          0.0187   4035.0000\n",
      "50%       16.7474         0.5890      0.0010          0.0252   4555.0000\n",
      "75%       17.0374         0.7282      0.0144          0.0357   5002.0000\n",
      "max       19.0526         1.0000      0.0974          0.1052  12998.0000\n",
      "\n",
      "================================================================================\n",
      "Stock: NVDA\n",
      "================================================================================\n",
      "       Log_Volume  net_sentiment  Log_Return  Intraday_Range  NewsCount\n",
      "count    541.0000       541.0000    541.0000        541.0000   541.0000\n",
      "mean      19.7689         0.6700      0.0026          0.0385    69.0092\n",
      "std        0.4685         0.2231      0.0333          0.0221    57.2829\n",
      "min       18.3993        -0.5307     -0.2038          0.0097     7.0000\n",
      "25%       19.4145         0.5741     -0.0128          0.0227    41.0000\n",
      "50%       19.7410         0.7239      0.0031          0.0333    54.0000\n",
      "75%       20.1265         0.8214      0.0223          0.0468    78.0000\n",
      "max       21.1042         1.0000      0.1579          0.1557   860.0000\n",
      "\n",
      "================================================================================\n",
      "Stock: TSLA\n",
      "================================================================================\n",
      "       Log_Volume  net_sentiment  Log_Return  Intraday_Range  NewsCount\n",
      "count    541.0000       541.0000    541.0000        541.0000   541.0000\n",
      "mean      18.5959         0.4766      0.0041          0.0519   326.0425\n",
      "std        0.6537         0.2389      0.0469          0.0315   211.7322\n",
      "min       17.1966        -0.5885     -0.2365          0.0085    33.0000\n",
      "25%       18.0805         0.3676     -0.0198          0.0304   195.0000\n",
      "50%       18.4692         0.5274      0.0026          0.0437   266.0000\n",
      "75%       19.1201         0.6416      0.0263          0.0630   390.0000\n",
      "max       20.6334         0.8738      0.1815          0.2494  1697.0000\n",
      "\n",
      "================================================================================\n",
      "4. Missing values by stock:\n",
      "------------------------------------------------------------\n",
      "AAPL: No missing values\n",
      "AMZN: No missing values\n",
      "FB: No missing values\n",
      "NVDA: No missing values\n",
      "TSLA: No missing values\n",
      "\n",
      "================================================================================\n",
      "5. Quick Summary Comparison:\n",
      "================================================================================\n",
      "           Log_Volume                           net_sentiment                  \\\n",
      "                 mean     std      min      max          mean     std     min   \n",
      "stock_name                                                                      \n",
      "AAPL          18.5197  0.4313  17.5291  19.8711        0.4797  0.2855 -0.4370   \n",
      "AMZN          18.1585  0.3838  17.1841  19.5564        0.6077  0.2001 -0.2105   \n",
      "FB            16.7962  0.4439  15.7179  19.0526        0.5502  0.2342 -0.3768   \n",
      "NVDA          19.7689  0.4685  18.3993  21.1042        0.6700  0.2231 -0.5307   \n",
      "TSLA          18.5959  0.6537  17.1966  20.6334        0.4766  0.2389 -0.5885   \n",
      "\n",
      "                   Log_Return                          NewsCount             \\\n",
      "               max       mean     std     min     max       mean        std   \n",
      "stock_name                                                                    \n",
      "AAPL        0.9325     0.0015  0.0233 -0.1377  0.1131   821.5749   379.5345   \n",
      "AMZN        0.9374     0.0009  0.0214 -0.0825  0.1269   705.0702   316.9192   \n",
      "FB          1.0000     0.0000  0.0278 -0.3064  0.0974  4540.3734  1093.1886   \n",
      "NVDA        1.0000     0.0026  0.0333 -0.2038  0.1579    69.0092    57.2829   \n",
      "TSLA        0.8738     0.0041  0.0469 -0.2365  0.1815   326.0425   211.7322   \n",
      "\n",
      "                        \n",
      "            min    max  \n",
      "stock_name              \n",
      "AAPL         72   3910  \n",
      "AMZN         55   3571  \n",
      "FB          469  12998  \n",
      "NVDA          7    860  \n",
      "TSLA         33   1697  \n"
     ]
    }
   ],
   "source": [
    "# Check data distribution by stock\n",
    "print(\"=\"*80)\n",
    "print(\"Data Distribution by Stock\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Reset index temporarily to access stock_name column\n",
    "df_temp = df_final.reset_index()\n",
    "\n",
    "# 1. Number of observations per stock\n",
    "print(\"\\n1. Number of observations per stock:\")\n",
    "print(\"-\"*60)\n",
    "stock_counts = df_temp['stock_name'].value_counts().sort_index()\n",
    "print(stock_counts)\n",
    "print(f\"\\nTotal observations: {len(df_temp)}\")\n",
    "\n",
    "# 2. Date range for each stock\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. Date range for each stock:\")\n",
    "print(\"-\"*60)\n",
    "for stock in sorted(df_temp['stock_name'].unique()):\n",
    "    stock_data = df_temp[df_temp['stock_name'] == stock]\n",
    "    print(f\"{stock:5s}: {stock_data['date'].min().date()} to {stock_data['date'].max().date()} ({len(stock_data)} trading days)\")\n",
    "\n",
    "# 3. Descriptive statistics for key variables by stock\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. Descriptive Statistics by Stock:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "key_vars = ['Log_Volume', 'net_sentiment', 'Log_Return', 'Intraday_Range', 'NewsCount']\n",
    "\n",
    "for stock in sorted(df_temp['stock_name'].unique()):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Stock: {stock}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    stock_data = df_temp[df_temp['stock_name'] == stock]\n",
    "    print(stock_data[key_vars].describe().round(4))\n",
    "\n",
    "# 4. Check for missing values by stock\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. Missing values by stock:\")\n",
    "print(\"-\"*60)\n",
    "for stock in sorted(df_temp['stock_name'].unique()):\n",
    "    stock_data = df_temp[df_temp['stock_name'] == stock]\n",
    "    missing = stock_data.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(f\"\\n{stock}:\")\n",
    "        print(missing[missing > 0])\n",
    "    else:\n",
    "        print(f\"{stock}: No missing values\")\n",
    "\n",
    "# 5. Quick summary comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. Quick Summary Comparison:\")\n",
    "print(\"=\"*80)\n",
    "summary_stats = df_temp.groupby('stock_name')[['Log_Volume', 'net_sentiment', 'Log_Return', 'NewsCount']].agg(['mean', 'std', 'min', 'max'])\n",
    "print(summary_stats.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "09f06327",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('final_merged_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compss211",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
